#include "gpu_demo/QuadricDetect.h"
#include "gpu_demo/QuadricDetect_kernels.cuh"
#include <cusolverDn.h>
#include <thrust/device_vector.h>
#include <thrust/sequence.h>
#include <ctime>
#include <iostream>
#include <cmath>     // æ·»åŠ è¿™ä¸ªå¤´æ–‡ä»¶ç”¨äºisfiniteå‡½æ•°
#include <algorithm> // æ·»åŠ è¿™ä¸ªå¤´æ–‡ä»¶ç”¨äºminå‡½æ•°
#include <stdexcept> // ç”¨äº std::exception

// ========================================
// CUDAå†…æ ¸å‡½æ•°å®šä¹‰ (æ¯ä¸ªå†…æ ¸åªå®šä¹‰ä¸€æ¬¡!)
// ========================================

__global__ void initCurandStates_Kernel(curandState *states, unsigned long seed, int n)
{
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n)
    {
        curand_init(seed, idx, 0, &states[idx]);
    }
}

__global__ void sampleAndBuildMatrices_Kernel(
    const GPUPoint3f *all_points,
    const int *remaining_indices,
    int num_remaining,
    curandState *rand_states,
    int batch_size,
    float *batch_matrices)
{
    int model_id = blockIdx.x * blockDim.x + threadIdx.x;
    if (model_id >= batch_size)
        return;

    curandState local_state = rand_states[model_id];

    // é‡‡æ ·9ä¸ªç‚¹
    int sample_indices[9];
    for (int i = 0; i < 9; ++i)
    {
        sample_indices[i] = remaining_indices[curand(&local_state) % num_remaining];
    }

    // æ„é€ 9x10çš„AçŸ©é˜µ (ğŸ”§ ä¿®å¤ï¼šæŒ‰åˆ—ä¸»åºå­˜å‚¨ï¼Œç¬¦åˆcuSolverè¦æ±‚)
    float *A = &batch_matrices[model_id * 90]; // 9*10

    for (int i = 0; i < 9; ++i)
    {
        GPUPoint3f pt = all_points[sample_indices[i]];
        float x = pt.x, y = pt.y, z = pt.z;

        // ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥å¹¶å¤„ç†æ— æ•ˆçš„ç‚¹äº‘æ•°æ®
        if (!isfinite(x) || !isfinite(y) || !isfinite(z) ||
            isnan(x) || isnan(y) || isnan(z) ||
            isinf(x) || isinf(y) || isinf(z))
        {
            // ğŸš¨ å‘ç°æ— æ•ˆç‚¹ï¼Œç”¨é»˜è®¤å€¼æ›¿æ¢
            x = 0.0f;
            y = 0.0f;
            z = 0.0f;
        }

        // ğŸ¯ å…³é”®ä¿®å¤ï¼šåˆ—ä¸»åºå­˜å‚¨ A[col * m + row]
        A[0 * 9 + i] = x * x; // xÂ² (ç¬¬0åˆ—)
        A[1 * 9 + i] = y * y; // yÂ² (ç¬¬1åˆ—)
        A[2 * 9 + i] = z * z; // zÂ² (ç¬¬2åˆ—)
        A[3 * 9 + i] = x * y; // xy (ç¬¬3åˆ—)
        A[4 * 9 + i] = x * z; // xz (ç¬¬4åˆ—)
        A[5 * 9 + i] = y * z; // yz (ç¬¬5åˆ—)
        A[6 * 9 + i] = x;     // x  (ç¬¬6åˆ—)
        A[7 * 9 + i] = y;     // y  (ç¬¬7åˆ—)
        A[8 * 9 + i] = z;     // z  (ç¬¬8åˆ—)
        A[9 * 9 + i] = 1.0f;  // å¸¸æ•°é¡¹ (ç¬¬9åˆ—)

        // ğŸ”§ äºŒæ¬¡éªŒè¯ï¼šç¡®ä¿ç”Ÿæˆçš„å€¼éƒ½æ˜¯æœ‰æ•ˆçš„
        for (int col = 0; col < 10; ++col)
        {
            float val = A[col * 9 + i];
            if (!isfinite(val) || isnan(val) || isinf(val))
            {
                A[col * 9 + i] = (col == 9) ? 1.0f : 0.0f; // å¸¸æ•°é¡¹è®¾ä¸º1ï¼Œå…¶ä»–è®¾ä¸º0
            }
        }
    }

    rand_states[model_id] = local_state;
}

__global__ void countInliersBatch_Kernel(
    const GPUPoint3f *all_points,
    const int *remaining_indices,
    int num_remaining,
    const GPUQuadricModel *batch_models,
    int batch_size,
    float threshold,
    int *batch_inlier_counts)
{
    int model_id = blockIdx.y; // ä½¿ç”¨2D gridï¼Œyç»´åº¦å¯¹åº”æ¨¡å‹
    if (model_id >= batch_size)
        return;

    int thread_id = blockIdx.x * blockDim.x + threadIdx.x;
    int local_count = 0;

    // æ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªç‚¹
    for (int i = thread_id; i < num_remaining; i += blockDim.x * gridDim.x)
    {
        GPUPoint3f point = all_points[remaining_indices[i]];
        float dist = evaluateQuadricDistance(point, batch_models[model_id]);

        if (dist < threshold)
        {
            local_count++;
        }
    }

    // Blockå†…reduceæ±‚å’Œ
    __shared__ int shared_counts[256];
    shared_counts[threadIdx.x] = local_count;
    __syncthreads();

    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)
    {
        if (threadIdx.x < stride)
        {
            shared_counts[threadIdx.x] += shared_counts[threadIdx.x + stride];
        }
        __syncthreads();
    }

    if (threadIdx.x == 0)
    {
        atomicAdd(&batch_inlier_counts[model_id], shared_counts[0]);
    }
}

__device__ inline float evaluateQuadricDistance(
    const GPUPoint3f &point,
    const GPUQuadricModel &model)
{
    float x = point.x, y = point.y, z = point.z;

    // ğŸ”§ ä¿®å¤å¼€å§‹ï¼šæ·»åŠ è¾“å…¥éªŒè¯
    // éªŒè¯è¾“å…¥ç‚¹çš„æœ‰æ•ˆæ€§
    if (!isfinite(x) || !isfinite(y) || !isfinite(z) ||
        isnan(x) || isnan(y) || isnan(z) ||
        isinf(x) || isinf(y) || isinf(z))
    {
        return 1e10f; // è¿”å›ä¸€ä¸ªå¾ˆå¤§çš„è·ç¦»ï¼Œè¡¨ç¤ºæ— æ•ˆç‚¹
    }

    // éªŒè¯æ¨¡å‹ç³»æ•°çš„æœ‰æ•ˆæ€§
    bool model_valid = true;
    for (int i = 0; i < 16; ++i)
    {
        if (!isfinite(model.coeffs[i]) || isnan(model.coeffs[i]) || isinf(model.coeffs[i]))
        {
            model_valid = false;
            break;
        }
    }

    if (!model_valid)
    {
        return 1e10f; // è¿”å›ä¸€ä¸ªå¾ˆå¤§çš„è·ç¦»ï¼Œè¡¨ç¤ºæ— æ•ˆæ¨¡å‹
    }
    // ğŸ”§ ä¿®å¤ç»“æŸ

    // æ‰‹å†™äºŒæ¬¡å‹è®¡ç®—: [x y z 1] * Q * [x y z 1]^T
    float result = 0.0f;
    float coords[4] = {x, y, z, 1.0f};

    // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ›´å®‰å…¨çš„çŸ©é˜µä¹˜æ³•ï¼Œé¿å…æ½œåœ¨çš„å†…å­˜è®¿é—®é—®é¢˜
    for (int i = 0; i < 4; ++i)
    {
        for (int j = 0; j < 4; ++j)
        {
            int idx = i * 4 + j;      // ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if (idx >= 0 && idx < 16) // ğŸ”§ æ·»åŠ è¾¹ç•Œæ£€æŸ¥
            {
                float coeff = model.coeffs[idx];
                // ğŸ”§ éªŒè¯æ¯æ¬¡ä¹˜æ³•çš„ç»“æœ
                float term = coords[i] * coeff * coords[j];
                if (isfinite(term) && !isnan(term) && !isinf(term))
                {
                    result += term;
                }
            }
        }
    }

    // ğŸ”§ ä¿®å¤ï¼šéªŒè¯æœ€ç»ˆç»“æœçš„æœ‰æ•ˆæ€§
    if (!isfinite(result) || isnan(result) || isinf(result))
    {
        return 1e10f; // è¿”å›ä¸€ä¸ªå¾ˆå¤§çš„è·ç¦»ï¼Œè¡¨ç¤ºè®¡ç®—å¤±è´¥
    }

    return fabsf(result);
}

__global__ void findBestModel_Kernel(
    const int *batch_inlier_counts,
    int batch_size,
    int *best_index,
    int *best_count)
{
    int thread_id = threadIdx.x;
    int local_best_idx = -1;
    int local_best_count = 0;

    // æ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªæ¨¡å‹
    for (int i = thread_id; i < batch_size; i += blockDim.x)
    {
        if (batch_inlier_counts[i] > local_best_count)
        {
            local_best_count = batch_inlier_counts[i];
            local_best_idx = i;
        }
    }

    // Blockå†…reduceæ‰¾æœ€å¤§å€¼
    __shared__ int shared_counts[256];
    __shared__ int shared_indices[256];

    shared_counts[thread_id] = local_best_count;
    shared_indices[thread_id] = local_best_idx;
    __syncthreads();

    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)
    {
        if (thread_id < stride)
        {
            if (shared_counts[thread_id + stride] > shared_counts[thread_id])
            {
                shared_counts[thread_id] = shared_counts[thread_id + stride];
                shared_indices[thread_id] = shared_indices[thread_id + stride];
            }
        }
        __syncthreads();
    }

    if (thread_id == 0)
    {
        *best_count = shared_counts[0];
        *best_index = shared_indices[0];
    }
}

__global__ void extractInliers_Kernel(
    const GPUPoint3f *all_points,
    const int *remaining_indices,
    int num_remaining,
    const GPUQuadricModel *model,
    float threshold,
    int *inlier_indices,
    int *inlier_count)
{
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= num_remaining)
        return;

    // ğŸ”§ ä¿®å¤å¼€å§‹ï¼šæ·»åŠ æ›´å¤šå®‰å…¨æ£€æŸ¥
    // æ£€æŸ¥è¾“å…¥å‚æ•°æœ‰æ•ˆæ€§
    if (all_points == nullptr || remaining_indices == nullptr ||
        model == nullptr || inlier_indices == nullptr || inlier_count == nullptr)
    {
        return; // é™é»˜è¿”å›ï¼Œé¿å…åœ¨GPUä¸Šæ‰“å°é”™è¯¯
    }

    // æ£€æŸ¥ç´¢å¼•è¾¹ç•Œ
    int global_point_index = remaining_indices[idx];
    if (global_point_index < 0)
    {
        return; // æ— æ•ˆçš„ç‚¹ç´¢å¼•
    }

    // ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿æˆ‘ä»¬ä¸è®¿é—®è¶…å‡ºall_pointsæ•°ç»„è¾¹ç•Œçš„å†…å­˜
    // æ³¨æ„ï¼šæˆ‘ä»¬æ— æ³•åœ¨GPUå†…æ ¸ä¸­ç›´æ¥è·å–all_pointsçš„å¤§å°ï¼Œæ‰€ä»¥éœ€è¦ä¾èµ–è°ƒç”¨æ–¹ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ

    GPUPoint3f point = all_points[global_point_index];

    // ğŸ”§ éªŒè¯ç‚¹çš„æœ‰æ•ˆæ€§
    if (!isfinite(point.x) || !isfinite(point.y) || !isfinite(point.z) ||
        isnan(point.x) || isnan(point.y) || isnan(point.z) ||
        isinf(point.x) || isinf(point.y) || isinf(point.z))
    {
        return; // è·³è¿‡æ— æ•ˆç‚¹
    }

    float dist = evaluateQuadricDistance(point, *model);

    // ğŸ”§ éªŒè¯è·ç¦»è®¡ç®—ç»“æœçš„æœ‰æ•ˆæ€§
    if (!isfinite(dist) || isnan(dist) || isinf(dist))
    {
        return; // è·³è¿‡æ— æ•ˆè·ç¦»è®¡ç®—ç»“æœ
    }
    // ğŸ”§ ä¿®å¤ç»“æŸ

    if (dist < threshold)
    {
        // ğŸ”§ ä¿®å¤å¼€å§‹ï¼šæ·»åŠ è¾¹ç•Œæ£€æŸ¥é˜²æ­¢æ•°ç»„è¶Šç•Œ
        int write_pos = atomicAdd(inlier_count, 1);

        // ğŸ”§ å…³é”®å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ä¸ä¼šè¶Šç•Œè®¿é—®
        // ç†è®ºä¸Š d_temp_inlier_indices_ å¤§å°ç­‰äº d_remaining_indices_.size()
        // æ‰€ä»¥ write_pos åº”è¯¥æ°¸è¿œ < num_remainingï¼Œä½†ä¸ºäº†å®‰å…¨è¿˜æ˜¯æ£€æŸ¥
        if (write_pos < num_remaining)
        {
            inlier_indices[write_pos] = global_point_index;
        }
        else
        {
            // ğŸš¨ å¦‚æœå‘ç”Ÿè¶Šç•Œï¼Œè‡³å°‘ä¸ä¼šå´©æºƒï¼Œä½†ä¼šä¸¢å¤±è¿™ä¸ªå†…ç‚¹
            // åœ¨å®é™…åº”ç”¨ä¸­è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿ
            atomicAdd(inlier_count, -1); // å›æ»šè®¡æ•°å™¨
        }
        // ğŸ”§ ä¿®å¤ç»“æŸ
    }
} // ========================================
// æˆå‘˜å‡½æ•°å®ç° (æ¯ä¸ªå‡½æ•°åªå®šä¹‰ä¸€æ¬¡!)
// ========================================

void QuadricDetect::initializeGPUMemory(int batch_size)
{
    // åˆ†é…GPUå†…å­˜
    d_batch_matrices_.resize(batch_size * 9 * 10);
    d_batch_models_.resize(batch_size);
    d_batch_inlier_counts_.resize(batch_size);
    d_rand_states_.resize(batch_size);

    // åˆå§‹åŒ–ç»“æœå­˜å‚¨
    d_best_model_index_.resize(1);
    d_best_model_count_.resize(1);

    // ğŸ†• æ·»åŠ åå¹‚è¿­ä»£ç›¸å…³
    d_batch_ATA_matrices_.resize(batch_size * 10 * 10);
    d_batch_R_matrices_.resize(batch_size * 10 * 10);
    d_batch_eigenvectors_.resize(batch_size * 10);
}

void QuadricDetect::uploadPointsToGPU(const std::vector<GPUPoint3f> &h_points)
{
    //  å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶æ¸…ç©ºæ—§æ•°æ®ï¼Œé˜²æ­¢å¤šå¸§å¤ç”¨æ—¶çš„å†…å­˜æ±¡æŸ“
    d_all_points_.clear();
    d_remaining_indices_.clear();

    // é‡æ–°ä¸Šä¼ æ–°æ•°æ®
    d_all_points_ = h_points;
    d_remaining_indices_.resize(h_points.size());
    thrust::sequence(d_remaining_indices_.begin(), d_remaining_indices_.end(), 0);
}

void QuadricDetect::launchInitCurandStates(int batch_size)
{
    dim3 block(256);
    dim3 grid((batch_size + block.x - 1) / block.x);

    initCurandStates_Kernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_rand_states_.data()),
        time(nullptr),
        batch_size);
    cudaStreamSynchronize(stream_);
}

void QuadricDetect::launchSampleAndBuildMatrices(int batch_size)
{
    if (params_.verbosity > 0)
    {
        std::cout << "[launchSampleAndBuildMatrices] å¼€å§‹ç”Ÿæˆæ‰¹é‡çŸ©é˜µï¼Œbatch_size=" << batch_size << std::endl;
        std::cout << "  - å‰©ä½™ç‚¹æ•°: " << d_remaining_indices_.size() << std::endl;
        std::cout << "  - æ€»ç‚¹æ•°: " << d_all_points_.size() << std::endl;
    }

    // ğŸ” éªŒè¯è¾“å…¥æ•°æ®
    if (d_remaining_indices_.size() < 9)
    {
        std::cerr << "[launchSampleAndBuildMatrices] ğŸš¨ é”™è¯¯ï¼šå‰©ä½™ç‚¹æ•°ä¸è¶³9ä¸ªï¼Œæ— æ³•ç”ŸæˆçŸ©é˜µï¼" << std::endl;
        return;
    }

    if (d_all_points_.size() == 0)
    {
        std::cerr << "[launchSampleAndBuildMatrices] ğŸš¨ é”™è¯¯ï¼šç‚¹äº‘æ•°æ®ä¸ºç©ºï¼" << std::endl;
        return;
    }

    // ğŸ”§ æ–°å¢ï¼šéªŒè¯ç‚¹äº‘æ•°æ®çš„æœ‰æ•ˆæ€§
    if (params_.verbosity > 1)
    {
        std::cout << "[launchSampleAndBuildMatrices] ğŸ” éªŒè¯è¾“å…¥ç‚¹äº‘æ•°æ®æœ‰æ•ˆæ€§..." << std::endl;

        // æ£€æŸ¥å‰å‡ ä¸ªç‚¹çš„æ•°æ®
        thrust::host_vector<GPUPoint3f> h_sample_points(std::min(10, (int)d_all_points_.size()));
        cudaMemcpy(h_sample_points.data(),
                   thrust::raw_pointer_cast(d_all_points_.data()),
                   h_sample_points.size() * sizeof(GPUPoint3f),
                   cudaMemcpyDeviceToHost);

        int invalid_points = 0;
        for (size_t i = 0; i < h_sample_points.size(); ++i)
        {
            const GPUPoint3f &pt = h_sample_points[i];
            if (!std::isfinite(pt.x) || !std::isfinite(pt.y) || !std::isfinite(pt.z) ||
                std::isnan(pt.x) || std::isnan(pt.y) || std::isnan(pt.z) ||
                std::isinf(pt.x) || std::isinf(pt.y) || std::isinf(pt.z))
            {
                invalid_points++;
                std::cout << "    ğŸš¨ å‘ç°æ— æ•ˆç‚¹[" << i << "]: ("
                          << pt.x << ", " << pt.y << ", " << pt.z << ")" << std::endl;
            }
        }

        if (invalid_points > 0)
        {
            std::cout << "    ğŸš¨ è­¦å‘Šï¼šè¾“å…¥ç‚¹äº‘åŒ…å« " << invalid_points << " ä¸ªæ— æ•ˆç‚¹ï¼" << std::endl;
            std::cout << "    è¿™å¯èƒ½å¯¼è‡´SVDè®¡ç®—å¤±è´¥ï¼Œå»ºè®®é¢„å¤„ç†ç‚¹äº‘æ•°æ®" << std::endl;
        }
        else
        {
            std::cout << "    âœ“ è¾“å…¥ç‚¹äº‘æ•°æ®æœ‰æ•ˆ" << std::endl;
        }
    }

    dim3 block(256);
    dim3 grid((batch_size + block.x - 1) / block.x);

    // ğŸ” å…ˆæ¸…é›¶çŸ©é˜µæ•°æ®ï¼Œç¡®ä¿æ²¡æœ‰åƒåœ¾æ•°æ®
    thrust::fill(d_batch_matrices_.begin(), d_batch_matrices_.end(), 0.0f);

    sampleAndBuildMatrices_Kernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_all_points_.data()),
        thrust::raw_pointer_cast(d_remaining_indices_.data()),
        static_cast<int>(d_remaining_indices_.size()),
        thrust::raw_pointer_cast(d_rand_states_.data()),
        batch_size,
        thrust::raw_pointer_cast(d_batch_matrices_.data()));

    cudaError_t kernel_error = cudaGetLastError();
    if (kernel_error != cudaSuccess)
    {
        std::cerr << "[launchSampleAndBuildMatrices] ğŸš¨ å†…æ ¸å¯åŠ¨é”™è¯¯: " << cudaGetErrorString(kernel_error) << std::endl;
        return;
    }

    cudaStreamSynchronize(stream_);

    cudaError_t sync_error = cudaGetLastError();
    if (sync_error != cudaSuccess)
    {
        std::cerr << "[launchSampleAndBuildMatrices] ğŸš¨ å†…æ ¸æ‰§è¡Œé”™è¯¯: " << cudaGetErrorString(sync_error) << std::endl;
        return;
    }

    // ğŸ” éªŒè¯ç”Ÿæˆçš„çŸ©é˜µæ•°æ®
    if (params_.verbosity > 1)
    {
        std::cout << "[launchSampleAndBuildMatrices] éªŒè¯ç”Ÿæˆçš„çŸ©é˜µ..." << std::endl;

        // æ£€æŸ¥ç¬¬ä¸€ä¸ªçŸ©é˜µ
        thrust::host_vector<float> h_first_matrix(9 * 10);
        cudaMemcpy(h_first_matrix.data(),
                   thrust::raw_pointer_cast(d_batch_matrices_.data()),
                   9 * 10 * sizeof(float),
                   cudaMemcpyDeviceToHost);

        bool all_zero = true;
        for (int i = 0; i < 9 * 10; ++i)
        {
            if (h_first_matrix[i] != 0.0f)
            {
                all_zero = false;
                break;
            }
        }

        if (all_zero)
        {
            std::cerr << "[launchSampleAndBuildMatrices] ğŸš¨ ç”Ÿæˆçš„çŸ©é˜µå…¨ä¸ºé›¶ï¼æ£€æŸ¥å†…æ ¸å®ç°" << std::endl;

            // ğŸ” æ£€æŸ¥è¾“å…¥ç‚¹äº‘æ•°æ®
            thrust::host_vector<GPUPoint3f> h_points_sample(std::min(10, (int)d_all_points_.size()));
            cudaMemcpy(h_points_sample.data(),
                       thrust::raw_pointer_cast(d_all_points_.data()),
                       h_points_sample.size() * sizeof(GPUPoint3f),
                       cudaMemcpyDeviceToHost);

            std::cout << "  - å‰å‡ ä¸ªç‚¹äº‘æ•°æ®æ ·æœ¬:" << std::endl;
            for (size_t i = 0; i < h_points_sample.size(); ++i)
            {
                std::cout << "    ç‚¹" << i << ": (" << h_points_sample[i].x
                          << ", " << h_points_sample[i].y
                          << ", " << h_points_sample[i].z << ")" << std::endl;
            }

            // ğŸ” æ£€æŸ¥å‰©ä½™ç´¢å¼•
            thrust::host_vector<int> h_indices_sample(std::min(10, (int)d_remaining_indices_.size()));
            cudaMemcpy(h_indices_sample.data(),
                       thrust::raw_pointer_cast(d_remaining_indices_.data()),
                       h_indices_sample.size() * sizeof(int),
                       cudaMemcpyDeviceToHost);

            std::cout << "  - å‰å‡ ä¸ªå‰©ä½™ç´¢å¼•:" << std::endl;
            for (size_t i = 0; i < h_indices_sample.size(); ++i)
            {
                std::cout << "    ç´¢å¼•" << i << ": " << h_indices_sample[i] << std::endl;
            }
        }
        else
        {
            std::cout << "[launchSampleAndBuildMatrices] âœ“ çŸ©é˜µç”ŸæˆæˆåŠŸï¼ŒåŒ…å«éé›¶æ•°æ®" << std::endl;
        }
    }

    if (params_.verbosity > 0)
    {
        std::cout << "[launchSampleAndBuildMatrices] çŸ©é˜µç”Ÿæˆå®Œæˆ" << std::endl;
    }
}

void QuadricDetect::launchCountInliersBatch(int batch_size)
{
    // ä¿®å¤: ä½¿ç”¨2D gridåŒ¹é…å†…æ ¸å®ç°
    dim3 block(256);
    dim3 grid_x((d_remaining_indices_.size() + block.x - 1) / block.x);
    dim3 grid(grid_x.x, batch_size); // 2D grid: (points, models)

    // å…ˆæ¸…é›¶è®¡æ•°å™¨
    thrust::fill(d_batch_inlier_counts_.begin(), d_batch_inlier_counts_.end(), 0);

    countInliersBatch_Kernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_all_points_.data()),
        thrust::raw_pointer_cast(d_remaining_indices_.data()),
        static_cast<int>(d_remaining_indices_.size()),
        thrust::raw_pointer_cast(d_batch_models_.data()),
        batch_size,
        static_cast<float>(params_.quadric_distance_threshold),
        thrust::raw_pointer_cast(d_batch_inlier_counts_.data()));
    cudaStreamSynchronize(stream_);
}

void QuadricDetect::launchFindBestModel(int batch_size)
{
    findBestModel_Kernel<<<1, 256, 0, stream_>>>(
        thrust::raw_pointer_cast(d_batch_inlier_counts_.data()),
        batch_size,
        thrust::raw_pointer_cast(d_best_model_index_.data()),
        thrust::raw_pointer_cast(d_best_model_count_.data()));
    cudaStreamSynchronize(stream_);
}

// æ›¿æ¢ä½  QuadricDetect.cu æ–‡ä»¶ä¸­çš„å ä½ç¬¦å®ç°ï¼š
void QuadricDetect::launchExtractInliers(const GPUQuadricModel *model)
{
    if (params_.verbosity > 0)
    {
        std::cout << "[launchExtractInliers] å¼€å§‹æå–å†…ç‚¹ç´¢å¼•" << std::endl;
    }

    // ä¿®å¤å¼€å§‹ï¼šæ·»åŠ è¯¦ç»†çš„è¾“å…¥éªŒè¯
    // std::cout << "debug1" << std::endl;

    // éªŒè¯è¾“å…¥å‚æ•°
    if (model == nullptr)
    {
        std::cerr << "[launchExtractInliers]  é”™è¯¯ï¼šmodelæŒ‡é’ˆä¸ºç©ºï¼" << std::endl;
        current_inlier_count_ = 0;
        return;
    }

    if (d_remaining_indices_.size() == 0)
    {
        std::cerr << "[launchExtractInliers] é”™è¯¯ï¼šæ²¡æœ‰å‰©ä½™ç‚¹å¯å¤„ç†ï¼" << std::endl;
        current_inlier_count_ = 0;
        return;
    }

    if (d_all_points_.size() == 0)
    {
        std::cerr << "[launchExtractInliers] é”™è¯¯ï¼šç‚¹äº‘æ•°æ®ä¸ºç©ºï¼" << std::endl;
        current_inlier_count_ = 0;
        return;
    }

    std::cout << "  - å‰©ä½™ç‚¹æ•°: " << d_remaining_indices_.size() << std::endl;
    std::cout << "  - æ€»ç‚¹æ•°: " << d_all_points_.size() << std::endl;
    std::cout << "  - è·ç¦»é˜ˆå€¼: " << params_.quadric_distance_threshold << std::endl;

    // ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†modelä»CPUæ‹·è´åˆ°GPUä¸“ç”¨å†…å­˜
    thrust::device_vector<GPUQuadricModel> d_model_safe(1);
    d_model_safe[0] = *model; // å®‰å…¨æ‹·è´
    // std::cout << "debug1.5 - æ¨¡å‹å·²å®‰å…¨æ‹·è´åˆ°GPU" << std::endl;
    // ğŸ”§ ä¿®å¤ç»“æŸ

    // åˆ†é…ä¸´æ—¶GPUå†…å­˜å­˜å‚¨å†…ç‚¹ç´¢å¼•
    d_temp_inlier_indices_.resize(d_remaining_indices_.size());
    // std::cout << "debug2" << std::endl;
    thrust::device_vector<int> d_inlier_count(1, 0);
    // std::cout << "debug3" << std::endl;

    // é…ç½®CUDAç½‘æ ¼
    dim3 block(256);
    dim3 grid((d_remaining_indices_.size() + block.x - 1) / block.x);
    // std::cout << "debug3.5 - Gridé…ç½®: " << grid.x << " blocks, " << block.x << " threads" << std::endl;

    // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨çš„GPUå†…å­˜è€Œä¸æ˜¯CPUæŒ‡é’ˆ
    extractInliers_Kernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_all_points_.data()),
        thrust::raw_pointer_cast(d_remaining_indices_.data()),
        static_cast<int>(d_remaining_indices_.size()),
        thrust::raw_pointer_cast(d_model_safe.data()), // ğŸ”§ ä½¿ç”¨GPUå†…å­˜
        static_cast<float>(params_.quadric_distance_threshold),
        thrust::raw_pointer_cast(d_temp_inlier_indices_.data()),
        thrust::raw_pointer_cast(d_inlier_count.data()));
    // std::cout << "debug4" << std::endl;

    cudaStreamSynchronize(stream_);
    // std::cout << "debug5" << std::endl;

    // ğŸ”§ ä¿®å¤å¼€å§‹ï¼šä½¿ç”¨æ›´å®‰å…¨çš„å†…å­˜è®¿é—®æ–¹æ³•æ›¿ä»£thrust::copy
    // æ£€æŸ¥å†…æ ¸æ‰§è¡Œæ˜¯å¦æœ‰é”™è¯¯
    cudaError_t kernel_error = cudaGetLastError();
    if (kernel_error != cudaSuccess)
    {
        std::cerr << "[launchExtractInliers] å†…æ ¸æ‰§è¡Œé”™è¯¯: " << cudaGetErrorString(kernel_error) << std::endl;
        current_inlier_count_ = 0;
        return;
    }

    // è·å–å†…ç‚¹æ•°é‡å¹¶è°ƒæ•´å¤§å°
    // åŸå§‹ä»£ç  - å¯èƒ½å¯¼è‡´éæ³•å†…å­˜è®¿é—®ï¼š
    // thrust::host_vector<int> h_count = d_inlier_count;
    // thrust::host_vector<int> h_count(1);
    // thrust::copy(d_inlier_count.begin(), d_inlier_count.end(), h_count.begin());

    // ğŸ”§ æ–°æ–¹æ¡ˆï¼šä½¿ç”¨åŸç”ŸcudaMemcpyï¼Œæ›´å®‰å…¨å¯æ§
    int h_count_temp = 0;
    cudaError_t copy_error = cudaMemcpy(&h_count_temp,
                                        thrust::raw_pointer_cast(d_inlier_count.data()),
                                        sizeof(int),
                                        cudaMemcpyDeviceToHost);

    if (copy_error != cudaSuccess)
    {
        std::cerr << "[launchExtractInliers] ğŸš¨ å†…å­˜æ‹·è´é”™è¯¯: " << cudaGetErrorString(copy_error) << std::endl;
        current_inlier_count_ = 0;
        return;
    }

    current_inlier_count_ = h_count_temp;
    // ğŸ”§ ä¿®å¤ç»“æŸ

    // std::cout << "debug6" << std::endl;

    // åŸå§‹ä»£ç å·²ç§»é™¤ - ä¼šå¯¼è‡´ç¼–è¯‘é”™è¯¯ï¼š
    // current_inlier_count_ = h_count[0];

    // std::cout << "debug7" << std::endl;

    d_temp_inlier_indices_.resize(current_inlier_count_);
    // std::cout << "debug8" << std::endl;

    if (params_.verbosity > 0)
    {
        std::cout << "[launchExtractInliers] æ‰¾åˆ° " << current_inlier_count_ << " ä¸ªå†…ç‚¹" << std::endl;
    }
}

void QuadricDetect::getBestModelResults(thrust::host_vector<int> &h_best_index, thrust::host_vector<int> &h_best_count)
{
    // ä»deviceæ‹·è´åˆ°host
    h_best_index = d_best_model_index_;
    h_best_count = d_best_model_count_;
}

// removeçš„GPUå‡½æ•°å®ç°
// åœ¨ QuadricDetect.cu ä¸­æ·»åŠ å†…æ ¸
__global__ void removePointsKernel(
    const int *remaining_points,
    int remaining_count,
    const int *sorted_inliers, // å·²æ’åºçš„å†…ç‚¹ç´¢å¼•
    int inlier_count,
    int *output_points,
    int *output_count)
{
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= remaining_count)
        return;

    int point_id = remaining_points[idx];

    // GPUä¸ŠäºŒåˆ†æŸ¥æ‰¾
    bool is_inlier = false;
    int left = 0, right = inlier_count - 1;
    while (left <= right)
    {
        int mid = (left + right) / 2;
        if (sorted_inliers[mid] == point_id)
        {
            is_inlier = true;
            break;
        }
        if (sorted_inliers[mid] < point_id)
            left = mid + 1;
        else
            right = mid - 1;
    }

    // å¦‚æœä¸æ˜¯å†…ç‚¹ï¼Œå°±ä¿ç•™
    if (!is_inlier)
    {
        int write_pos = atomicAdd(output_count, 1);
        output_points[write_pos] = point_id;
    }
}

// åŒ…è£…å‡½æ•°
void QuadricDetect::launchRemovePointsKernel()
{
    // ä¿®å¤ï¼šæ·»åŠ è¾¹ç•Œæ£€æŸ¥ï¼Œé˜²æ­¢ radix_sort é”™è¯¯
    if (current_inlier_count_ <= 0)
    {
        if (params_.verbosity > 0)
        {
            std::cout << "[launchRemovePointsKernel] è·³è¿‡ï¼šå†…ç‚¹æ•°é‡ä¸º0" << std::endl;
        }
        return;
    }
    
    if (current_inlier_count_ > static_cast<int>(d_temp_inlier_indices_.size()))
    {
        std::cerr << "[launchRemovePointsKernel] é”™è¯¯ï¼šå†…ç‚¹æ•°é‡ (" << current_inlier_count_
                  << ") è¶…å‡ºæ•°ç»„å¤§å° (" << d_temp_inlier_indices_.size() << ")" << std::endl;
        return;
    }
    
    if (d_temp_inlier_indices_.empty())
    {
        std::cerr << "[launchRemovePointsKernel] é”™è¯¯ï¼šå†…ç‚¹ç´¢å¼•æ•°ç»„ä¸ºç©º" << std::endl;
        return;
    }
    
    // ç¡®ä¿ä¹‹å‰çš„ CUDA æ“ä½œå·²å®Œæˆ
    cudaError_t sync_error = cudaStreamSynchronize(stream_);
    if (sync_error != cudaSuccess)
    {
        std::cerr << "[launchRemovePointsKernel] CUDAæµåŒæ­¥é”™è¯¯: " 
                  << cudaGetErrorString(sync_error) << std::endl;
        return;
    }
    
    // 1. å¯¹å†…ç‚¹ç´¢å¼•æ’åºï¼ˆçº¯GPUæ“ä½œï¼‰
    try {
        thrust::sort(d_temp_inlier_indices_.begin(),
                     d_temp_inlier_indices_.begin() + current_inlier_count_);
        
        // æ£€æŸ¥æ’åºæ“ä½œæ˜¯å¦æœ‰é”™è¯¯
        cudaError_t sort_error = cudaGetLastError();
        if (sort_error != cudaSuccess)
        {
            std::cerr << "[launchRemovePointsKernel] æ’åºé”™è¯¯: " 
                      << cudaGetErrorString(sort_error) << std::endl;
            return;
        }
    }
    catch (const std::exception &e)
    {
        std::cerr << "[launchRemovePointsKernel] æ’åºå¼‚å¸¸: " << e.what() << std::endl;
        return;
    }

    // 2. åˆ†é…è¾“å‡ºç©ºé—´
    thrust::device_vector<int> d_new_remaining(d_remaining_indices_.size());
    thrust::device_vector<int> d_output_count(1, 0);

    // 3. å¯åŠ¨å†…æ ¸
    dim3 block(256);
    dim3 grid((d_remaining_indices_.size() + block.x - 1) / block.x);

    removePointsKernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_remaining_indices_.data()),
        static_cast<int>(d_remaining_indices_.size()),
        thrust::raw_pointer_cast(d_temp_inlier_indices_.data()),
        current_inlier_count_,
        thrust::raw_pointer_cast(d_new_remaining.data()),
        thrust::raw_pointer_cast(d_output_count.data()));

    cudaStreamSynchronize(stream_);

    // 4. è·å–å®é™…è¾“å‡ºå¤§å°å¹¶è°ƒæ•´
    thrust::host_vector<int> h_count = d_output_count;
    int new_size = h_count[0]; //  è¿™é‡Œæœ‰ä¸€æ¬¡å°ä¼ è¾“ï¼Œä½†unavoidable

    d_new_remaining.resize(new_size);
    d_remaining_indices_ = std::move(d_new_remaining);
}

// æ–°å¢å‡½æ•°å®ç°--åå¹‚è¿­ä»£çš„æ ¸å¿ƒå®ç°
// æ·»åŠ åˆ°QuadricDetect.cu

// 1. è®¡ç®—A^T*AçŸ©é˜µ
__global__ void computeATA_Kernel(
    const float *batch_matrices, // è¾“å…¥ï¼š1024ä¸ª9Ã—10çŸ©é˜µ
    float *batch_ATA_matrices,   // è¾“å‡ºï¼š1024ä¸ª10Ã—10 A^T*AçŸ©é˜µ
    int batch_size)
{
    int batch_id = blockIdx.x * blockDim.x + threadIdx.x;
    if (batch_id >= batch_size)
        return;

    const float *A = &batch_matrices[batch_id * 90];  // 9Ã—10çŸ©é˜µ
    float *ATA = &batch_ATA_matrices[batch_id * 100]; // 10Ã—10çŸ©é˜µ

    // è®¡ç®—A^T * A
    for (int i = 0; i < 10; ++i)
    {
        for (int j = i; j < 10; ++j)
        { // åªè®¡ç®—ä¸Šä¸‰è§’ï¼Œåˆ©ç”¨å¯¹ç§°æ€§
            float sum = 0.0f;
            for (int k = 0; k < 9; ++k)
            {
                sum += A[i * 9 + k] * A[j * 9 + k]; // A^T[i][k] * A[j][k]
            }
            ATA[i * 10 + j] = sum;
            ATA[j * 10 + i] = sum; // å¯¹ç§°çŸ©é˜µ
        }
    }
}

__global__ void batchQR_Kernel(
    const float *batch_ATA_matrices,
    float *batch_R_matrices,
    int batch_size)
{
    int batch_id = blockIdx.x;
    if (batch_id >= batch_size)
        return;

    __shared__ float A[10][10];
    __shared__ float R[10][10];

    //  1. å…ˆåˆå§‹åŒ–RçŸ©é˜µä¸ºé›¶
    for (int i = threadIdx.x; i < 100; i += blockDim.x)
    {
        ((float *)R)[i] = 0.0f;
    }
    __syncthreads();

    // 2. åŠ è½½A^T*Aåˆ°å…±äº«å†…å­˜
    const float *ATA = &batch_ATA_matrices[batch_id * 100];
    for (int i = threadIdx.x; i < 100; i += blockDim.x)
    {
        ((float *)A)[i] = ATA[i];
    }
    __syncthreads();

    // 3. æ‰§è¡ŒGram-Schmidt QRåˆ†è§£
    for (int k = 0; k < 10; ++k)
    {
        if (threadIdx.x == 0)
        {
            // è®¡ç®—ç¬¬kåˆ—çš„æ¨¡é•¿
            float norm_sq = 0.0f;
            for (int i = k; i < 10; ++i)
            {
                norm_sq += A[i][k] * A[i][k];
            }
            float norm = sqrtf(norm_sq);

            // æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
            if (norm < 1e-12f)
            {
                for (int i = k; i < 10; ++i)
                {
                    A[i][k] = (i == k) ? 1.0f : 0.0f;
                }
                norm = 1.0f;
            }

            // å½’ä¸€åŒ–ç¬¬kåˆ—
            for (int i = k; i < 10; ++i)
            {
                A[i][k] /= norm;
            }

            //  è®¾ç½®R[k][k] (å¯¹è§’çº¿å…ƒç´ )
            R[k][k] = norm;

            // æ­£äº¤åŒ–åç»­åˆ—
            for (int j = k + 1; j < 10; ++j)
            {
                // è®¡ç®—æŠ•å½±ç³»æ•°
                float proj_coeff = 0.0f;
                for (int i = k; i < 10; ++i)
                {
                    proj_coeff += A[i][k] * A[i][j];
                }

                //  è®¾ç½®R[k][j] (ä¸Šä¸‰è§’å…ƒç´ )
                R[k][j] = proj_coeff;

                // ä»a_jä¸­å‡å»æŠ•å½±
                for (int i = k; i < 10; ++i)
                {
                    A[i][j] -= proj_coeff * A[i][k];
                }
            }
        }
        __syncthreads();
    }

    //  4. è¾“å‡ºRçŸ©é˜µ (ä¸è¦å†æ¸…é›¶äº†!)
    float *R_out = &batch_R_matrices[batch_id * 100];
    for (int i = threadIdx.x; i < 100; i += blockDim.x)
    {
        R_out[i] = ((float *)R)[i];
    }
}

// 3. åå¹‚è¿­ä»£å†…æ ¸
__global__ void batchInversePowerIteration_Kernel(
    const float *batch_R_matrices, // è¾“å…¥ï¼š1024ä¸ª10Ã—10 RçŸ©é˜µ
    float *batch_eigenvectors,     // è¾“å‡ºï¼š1024ä¸ª10ç»´æœ€å°ç‰¹å¾å‘é‡
    curandState *rand_states,      // éšæœºæ•°çŠ¶æ€
    int batch_size)
{
    int batch_id = blockIdx.x;
    if (batch_id >= batch_size)
        return;

    __shared__ float R[10][10]; // RçŸ©é˜µ
    __shared__ float x[10];     // å½“å‰å‘é‡
    __shared__ float y[10];     // ä¸´æ—¶å‘é‡

    // åŠ è½½RçŸ©é˜µ
    const float *R_in = &batch_R_matrices[batch_id * 100];
    for (int i = threadIdx.x; i < 100; i += blockDim.x)
    {
        ((float *)R)[i] = R_in[i];
    }

    // åˆå§‹åŒ–éšæœºå‘é‡
    if (threadIdx.x < 10)
    {
        curandState local_state = rand_states[batch_id * 10 + threadIdx.x];
        x[threadIdx.x] = curand_uniform(&local_state);
        rand_states[batch_id * 10 + threadIdx.x] = local_state;
    }
    __syncthreads();

    // åå¹‚è¿­ä»£ï¼š8æ¬¡è¿­ä»£
    for (int iter = 0; iter < 8; ++iter)
    {
        // è§£ R * y = x (å›ä»£æ³•)
        if (threadIdx.x == 0)
        {
            for (int i = 9; i >= 0; --i)
            {
                float sum = x[i];
                for (int j = i + 1; j < 10; ++j)
                {
                    sum -= R[i][j] * y[j];
                }
                y[i] = (fabsf(R[i][i]) > 1e-12f) ? sum / R[i][i] : 0.0f;
            }
        }
        __syncthreads();

        // å½’ä¸€åŒ– y -> x
        if (threadIdx.x == 0)
        {
            float norm = 0.0f;
            for (int i = 0; i < 10; ++i)
            {
                norm += y[i] * y[i];
            }
            norm = sqrtf(norm);
            if (norm > 1e-12f)
            {
                for (int i = 0; i < 10; ++i)
                {
                    x[i] = y[i] / norm;
                }
            }
        }
        __syncthreads();
    }

    // è¾“å‡ºæœ€ç»ˆç‰¹å¾å‘é‡
    float *output = &batch_eigenvectors[batch_id * 10];
    if (threadIdx.x < 10)
    {
        output[threadIdx.x] = x[threadIdx.x];
    }
}

// 4. æå–äºŒæ¬¡æ›²é¢æ¨¡å‹å†…æ ¸
__global__ void extractQuadricModels_Kernel(
    const float *batch_eigenvectors, // è¾“å…¥ï¼š1024ä¸ª10ç»´ç‰¹å¾å‘é‡
    GPUQuadricModel *batch_models,   // è¾“å‡ºï¼š1024ä¸ªäºŒæ¬¡æ›²é¢æ¨¡å‹
    int batch_size)
{
    int batch_id = blockIdx.x * blockDim.x + threadIdx.x;
    if (batch_id >= batch_size)
        return;

    const float *eigenvec = &batch_eigenvectors[batch_id * 10];
    GPUQuadricModel *model = &batch_models[batch_id];

    // åˆå§‹åŒ–coeffsæ•°ç»„
    for (int i = 0; i < 16; ++i)
    {
        model->coeffs[i] = 0.0f;
    }

    // L2å½’ä¸€åŒ–
    float norm_sq = 0.0f;
    for (int i = 0; i < 10; ++i)
    {
        norm_sq += eigenvec[i] * eigenvec[i];
    }
    float norm_factor = (norm_sq > 1e-12f) ? 1.0f / sqrtf(norm_sq) : 1.0f;

    // 10ç»´å‘é‡â†’16ç»´coeffsçš„æ˜ å°„ (4x4å¯¹ç§°çŸ©é˜µæŒ‰è¡Œä¸»åºå­˜å‚¨)
    // äºŒæ¬¡æ›²é¢æ–¹ç¨‹: AxÂ² + ByÂ² + CzÂ² + 2Dxy + 2Exz + 2Fyz + 2Gx + 2Hy + 2Iz + J = 0
    // å¯¹åº”ç‰¹å¾å‘é‡: [A, B, C, D, E, F, G, H, I, J]

    float A = eigenvec[0] * norm_factor; // xÂ²ç³»æ•°
    float B = eigenvec[1] * norm_factor; // yÂ²ç³»æ•°
    float C = eigenvec[2] * norm_factor; // zÂ²ç³»æ•°
    float D = eigenvec[3] * norm_factor; // xyç³»æ•°
    float E = eigenvec[4] * norm_factor; // xzç³»æ•°
    float F = eigenvec[5] * norm_factor; // yzç³»æ•°
    float G = eigenvec[6] * norm_factor; // xç³»æ•°
    float H = eigenvec[7] * norm_factor; // yç³»æ•°
    float I = eigenvec[8] * norm_factor; // zç³»æ•°
    float J = eigenvec[9] * norm_factor; // å¸¸æ•°é¡¹

    // 4Ã—4å¯¹ç§°çŸ©é˜µQçš„æ˜ å°„ (æŒ‰è¡Œä¸»åºå­˜å‚¨åˆ°coeffs[16])
    // Q = [[A,   D,   E,   G],
    //      [D,   B,   F,   H],
    //      [E,   F,   C,   I],
    //      [G,   H,   I,   J]]

    model->coeffs[0] = A;  // Q(0,0)
    model->coeffs[1] = D;  // Q(0,1)
    model->coeffs[2] = E;  // Q(0,2)
    model->coeffs[3] = G;  // Q(0,3)
    model->coeffs[4] = D;  // Q(1,0) = Q(0,1)
    model->coeffs[5] = B;  // Q(1,1)
    model->coeffs[6] = F;  // Q(1,2)
    model->coeffs[7] = H;  // Q(1,3)
    model->coeffs[8] = E;  // Q(2,0) = Q(0,2)
    model->coeffs[9] = F;  // Q(2,1) = Q(1,2)
    model->coeffs[10] = C; // Q(2,2)
    model->coeffs[11] = I; // Q(2,3)
    model->coeffs[12] = G; // Q(3,0) = Q(0,3)
    model->coeffs[13] = H; // Q(3,1) = Q(1,3)
    model->coeffs[14] = I; // Q(3,2) = Q(2,3)
    model->coeffs[15] = J; // Q(3,3)
}

// åŒ…è£…å‡½æ•°
// ğŸ†• æ·»åŠ åˆ°QuadricDetect.cu

void QuadricDetect::launchComputeATA(int batch_size)
{
    dim3 block(256);
    dim3 grid((batch_size + block.x - 1) / block.x);

    computeATA_Kernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_batch_matrices_.data()),
        thrust::raw_pointer_cast(d_batch_ATA_matrices_.data()),
        batch_size);
    cudaStreamSynchronize(stream_);
}

void QuadricDetect::launchBatchQR(int batch_size)
{
    dim3 block(256);
    dim3 grid(batch_size); // æ¯ä¸ªblockå¤„ç†ä¸€ä¸ªçŸ©é˜µ

    batchQR_Kernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_batch_ATA_matrices_.data()),
        thrust::raw_pointer_cast(d_batch_R_matrices_.data()),
        batch_size);
    cudaStreamSynchronize(stream_);
}

void QuadricDetect::launchBatchInversePower(int batch_size)
{
    dim3 block(256);
    dim3 grid(batch_size); // æ¯ä¸ªblockå¤„ç†ä¸€ä¸ªçŸ©é˜µ

    batchInversePowerIteration_Kernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_batch_R_matrices_.data()),
        thrust::raw_pointer_cast(d_batch_eigenvectors_.data()),
        thrust::raw_pointer_cast(d_rand_states_.data()),
        batch_size);
    cudaStreamSynchronize(stream_);
}

void QuadricDetect::launchExtractQuadricModels(int batch_size)
{
    dim3 block(256);
    dim3 grid((batch_size + block.x - 1) / block.x);

    extractQuadricModels_Kernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_batch_eigenvectors_.data()),
        thrust::raw_pointer_cast(d_batch_models_.data()),
        batch_size);
    cudaStreamSynchronize(stream_);
}

// é‡è½½å®ç°
void QuadricDetect::uploadPointsToGPU(const thrust::device_vector<GPUPoint3f> &h_points)
{
    //  å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶æ¸…ç©ºæ—§æ•°æ®ï¼Œé˜²æ­¢å¤šå¸§å¤ç”¨æ—¶çš„å†…å­˜æ±¡æŸ“
    d_all_points_.clear();
    d_remaining_indices_.clear();

    // é‡æ–°ä¸Šä¼ æ–°æ•°æ®
    d_all_points_ = h_points;
    d_remaining_indices_.resize(h_points.size());
    thrust::sequence(d_remaining_indices_.begin(), d_remaining_indices_.end(), 0);
}
