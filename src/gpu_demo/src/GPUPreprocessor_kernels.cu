#include <cuda_runtime.h>

#include <thrust/device_vector.h>
#include <thrust/host_vector.h>
#include <thrust/sort.h>
#include <thrust/reduce.h>
#include <thrust/sequence.h>
#include <thrust/transform.h>
#include <thrust/unique.h>
#include <thrust/gather.h>
#include <thrust/functional.h>
#include <thrust/scan.h>
#include <thrust/execution_policy.h>
#include <thrust/system/cuda/execution_policy.h>
#include <iostream>
#include <numeric>
#include <chrono>

#include "gpu_demo/GPUPreprocessor_kernels.cuh"
#include "gpu_demo/GPUPreprocessor.h"

// ========== GPU Kernelå®ç° (ä¿æŒä¸å˜) ==========
namespace VoxelFilter
{
    __device__ inline uint64_t computeVoxelHash(float x, float y, float z, float voxel_size)
    {
        // âœ… æ·»åŠ è¾“å…¥éªŒè¯
        if (!isfinite(x) || !isfinite(y) || !isfinite(z) || voxel_size <= 0.0f)
        {
            return 0; // è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
        }

        int vx = __float2int_rd(x / voxel_size);
        int vy = __float2int_rd(y / voxel_size);
        int vz = __float2int_rd(z / voxel_size);

        // âœ… é™åˆ¶èŒƒå›´ï¼Œé¿å…æº¢å‡º
        vx = max(-1048576, min(1048575, vx)); // Â±2^20
        vy = max(-1048576, min(1048575, vy)); // Â±2^20
        vz = max(-512, min(511, vz));         // Â±2^9

        uint32_t ux = static_cast<uint32_t>(vx + (1 << 20));
        uint32_t uy = static_cast<uint32_t>(vy + (1 << 20));
        uint32_t uz = static_cast<uint32_t>(vz + (1 << 9));

        uint64_t hash = (static_cast<uint64_t>(ux) << 32) |
                        (static_cast<uint64_t>(uy) << 10) |
                        static_cast<uint64_t>(uz);
        return hash;
    }

    __global__ void computeVoxelKeysKernel(
        const GPUPoint3f *points,
        uint64_t *voxel_keys,
        float voxel_size,
        int point_count)
    {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= point_count)
            return;

        const GPUPoint3f &point = points[idx];
        voxel_keys[idx] = computeVoxelHash(point.x, point.y, point.z, voxel_size);
    }
}

namespace OutlierRemoval
{
    __device__ inline float computeDistance(const GPUPoint3f &p1, const GPUPoint3f &p2);
    __device__ inline float computeDistance(const GPUPoint3f &p1, const GPUPoint3f &p2)
    {
        float dx = p1.x - p2.x;
        float dy = p1.y - p2.y;
        float dz = p1.z - p2.z;
        return sqrtf(dx * dx + dy * dy + dz * dz);
    }

    // å·²å¼ƒç”¨ï¼šO(NÂ²)æš´åŠ›å®ç°ï¼Œè¢«ç©ºé—´å“ˆå¸Œæ›¿ä»£
    __global__ void radiusOutlierKernel(
        const GPUPoint3f *points,
        bool *valid_flags,
        int point_count,
        float radius,
        int min_neighbors)
    {
        // ç©ºå®ç°ï¼Œä¸å†ä½¿ç”¨
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= point_count)
            return;
        valid_flags[idx] = true; // é»˜è®¤æ‰€æœ‰ç‚¹æœ‰æ•ˆ
    }

    // å·²å¼ƒç”¨ï¼šç»Ÿè®¡ç¦»ç¾¤ç‚¹ç§»é™¤ï¼Œæœªå®ç°
    __global__ void statisticalOutlierKernel(
        const GPUPoint3f *points,
        bool *valid_flags,
        int point_count,
        int k,
        float std_dev_multiplier)
    {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= point_count)
            return;
        valid_flags[idx] = true; // é»˜è®¤æ‰€æœ‰ç‚¹æœ‰æ•ˆ
    }
}

namespace NormalEstimation
{
    __global__ void estimateNormalsKernel(
        const GPUPoint3f *points,
        GPUPointNormal3f *points_with_normals,
        int point_count,
        float radius,
        int k)
    {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= point_count)
            return;

        points_with_normals[idx].x = points[idx].x;
        points_with_normals[idx].y = points[idx].y;
        points_with_normals[idx].z = points[idx].z;

        points_with_normals[idx].normal_x = 0.0f;
        points_with_normals[idx].normal_y = 0.0f;
        points_with_normals[idx].normal_z = 1.0f;
    }
}

namespace GroundRemoval
{
    __global__ void ransacGroundDetectionKernel(
        const GPUPoint3f *points,
        bool *ground_flags,
        int point_count,
        float threshold,
        int max_iterations)
    {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= point_count)
            return;
        ground_flags[idx] = (points[idx].z < threshold);
    }
}

namespace Utils
{
    __global__ void compactPointsKernel(
        const GPUPoint3f *input_points,
        const bool *valid_flags,
        GPUPoint3f *output_points,
        int *output_count,
        int point_count)
    {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= point_count)
            return;

        if (valid_flags[idx])
        {
            int output_idx = atomicAdd(output_count, 1);
            output_points[output_idx] = input_points[idx];
        }
    }

    __global__ void convertToPointNormalKernel(
        const GPUPoint3f *input_points,
        GPUPointNormal3f *output_points,
        int point_count)
    {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= point_count)
            return;

        output_points[idx].x = input_points[idx].x;
        output_points[idx].y = input_points[idx].y;
        output_points[idx].z = input_points[idx].z;
        output_points[idx].normal_x = 0.0f;
        output_points[idx].normal_y = 0.0f;
        output_points[idx].normal_z = 1.0f;
    }
}

// ========== æ ¸å¿ƒæ”¹é€ ï¼šGPUPreprocessoræˆå‘˜å‡½æ•° (å…¨GPUæ¡†æ¶é£æ ¼) ==========

void GPUPreprocessor::cuda_performNormalEstimation(
    GPUPoint3f *points, GPUPointNormal3f *points_with_normals,
    size_t point_count, float radius, int k)
{
    if (point_count == 0)
        return;

    dim3 block(256);
    dim3 grid((point_count + block.x - 1) / block.x);

    // ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æŒ‡é’ˆï¼Œé¿å…device_vectoræ„é€ 
    NormalEstimation::estimateNormalsKernel<<<grid, block, 0, stream_>>>(
        points, points_with_normals, point_count, radius, k);
    cudaStreamSynchronize(stream_);
}

size_t GPUPreprocessor::cuda_compactValidPoints(
    GPUPoint3f *input_points, bool *valid_flags,
    GPUPoint3f *output_points, size_t input_count)
{
    if (input_count == 0)
        return 0;

    // å¤åˆ¶valid_flagsåˆ°æˆå‘˜å˜é‡
    thrust::copy(thrust::device_ptr<bool>(valid_flags),
                 thrust::device_ptr<bool>(valid_flags + input_count),
                 d_valid_flags_.begin());

    d_output_points_.clear();
    d_output_points_.reserve(input_count);

    std::vector<GPUPoint3f> h_temp_output(input_count);
    thrust::device_vector<GPUPoint3f> d_temp_output = h_temp_output;

    auto new_end = thrust::copy_if(
        d_temp_points_.begin(), d_temp_points_.begin() + input_count,
        d_valid_flags_.begin(),
        d_temp_output.begin(),
        thrust::identity<bool>());

    size_t output_count = new_end - d_temp_output.begin();
    thrust::copy(d_temp_output.begin(), d_temp_output.begin() + output_count,
                 thrust::device_ptr<GPUPoint3f>(output_points));

    return output_count;
}

void GPUPreprocessor::cuda_convertToPointsWithNormals(
    GPUPoint3f *input_points, GPUPointNormal3f *output_points, size_t point_count)
{
    if (point_count == 0)
        return;

    dim3 block(256);
    dim3 grid((point_count + block.x - 1) / block.x);

    // ç›´æ¥æ“ä½œæŒ‡é’ˆï¼Œé¿å…device_vectoræ„é€ 
    Utils::convertToPointNormalKernel<<<grid, block, 0, stream_>>>(
        input_points, output_points, point_count);
    cudaStreamSynchronize(stream_);
}

// ========== åœ¨.cuæ–‡ä»¶æœ«å°¾æ·»åŠ æ‰€æœ‰GPUå†…å­˜ç®¡ç†å‡½æ•° ==========

void GPUPreprocessor::cuda_initializeMemory(size_t max_points)
{
    // åœ¨.cuæ–‡ä»¶ä¸­ï¼Œæ‰€æœ‰resizeéƒ½æ˜¯å®‰å…¨çš„
    // åªè°ƒæ•´å¤§å°ï¼Œä¸åˆå§‹åŒ–æ•°æ®ï¼Œç­‰å¾…åç»­å¡«å……
    if (d_voxel_keys_.size() < max_points)
    {
        d_voxel_keys_.resize(max_points);
    }
    if (d_valid_flags_.size() < max_points)
    {
        d_valid_flags_.resize(max_points);
    }
    if (d_neighbor_counts_.size() < max_points)
    {
        d_neighbor_counts_.resize(max_points);
    }
    if (d_knn_indices_.size() < max_points * 20)
    {
        d_knn_indices_.resize(max_points * 20);
    }
    if (d_knn_distances_.size() < max_points * 20)
    {
        d_knn_distances_.resize(max_points * 20);
    }
    if (d_voxel_boundaries_.size() < max_points)
    {
        d_voxel_boundaries_.resize(max_points);
    }
    if (d_unique_keys_.size() < max_points)
    {
        d_unique_keys_.resize(max_points);
    }

    // PODç»“æ„ä½“åªéœ€è¦reserveå³å¯ï¼Œå¤§å°ä¼šåœ¨ä½¿ç”¨æ—¶æ­£ç¡®è®¾ç½®
    d_temp_points_.reserve(max_points);
    d_output_points_.reserve(max_points);
    d_output_points_normal_.reserve(max_points);

    // é¢„åˆ†é…æ¡¶æ’åºç¼“å†²åŒº
    const int NUM_BUCKETS = 1024;  // æ¡¶æ•°é‡ï¼ˆå¯é…ç½®ï¼Œ1024è¶³å¤Ÿå¤„ç†å¤§éƒ¨åˆ†æƒ…å†µï¼‰
    if (d_bucket_indices_.size() < max_points)
    {
        d_bucket_indices_.resize(max_points);
    }
    if (d_temp_points_sort_.size() < max_points)
    {
        d_temp_points_sort_.resize(max_points);
    }
    if (d_temp_keys_sort_.size() < max_points)
    {
        d_temp_keys_sort_.resize(max_points);
    }
    if (d_bucket_counts_.size() < NUM_BUCKETS)
    {
        d_bucket_counts_.resize(NUM_BUCKETS);
    }
    if (d_bucket_offsets_.size() < NUM_BUCKETS)
    {
        d_bucket_offsets_.resize(NUM_BUCKETS);
    }
    if (d_bucket_positions_.size() < NUM_BUCKETS)
    {
        d_bucket_positions_.resize(NUM_BUCKETS);
    }
    if (d_min_max_keys_.size() < 2)
    {
        d_min_max_keys_.resize(2);
    }
}
void GPUPreprocessor::cuda_launchVoxelFilter(float voxel_size)
{
    auto total_start = std::chrono::high_resolution_clock::now();
    std::cout << "[GPUPreprocessor] Starting voxel filter with size " << voxel_size << std::endl;

    size_t input_count = d_temp_points_.size();
    if (input_count == 0)
        return;

    // Step 1: å‡†å¤‡å†…å­˜
    auto memory_start = std::chrono::high_resolution_clock::now();
    d_voxel_keys_.clear();
    d_voxel_keys_.resize(input_count);
    auto memory_end = std::chrono::high_resolution_clock::now();
    float memory_time = std::chrono::duration<float, std::milli>(memory_end - memory_start).count();

    // Step 2: è®¡ç®—ä½“ç´ keys
    auto kernel_start = std::chrono::high_resolution_clock::now();
    dim3 block(256);
    dim3 grid((input_count + block.x - 1) / block.x);

    VoxelFilter::computeVoxelKeysKernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_temp_points_.data()),
        thrust::raw_pointer_cast(d_voxel_keys_.data()),
        voxel_size,
        static_cast<int>(input_count));

    cudaError_t kernel_error = cudaGetLastError();
    if (kernel_error != cudaSuccess)
    {
        std::cerr << "[ERROR] Voxel kernel failed: " << cudaGetErrorString(kernel_error) << std::endl;
        return;
    }
    cudaStreamSynchronize(stream_);
    auto kernel_end = std::chrono::high_resolution_clock::now();
    float kernel_time = std::chrono::duration<float, std::milli>(kernel_end - kernel_start).count();

    // Step 3: å¤§å°æ£€æŸ¥
    auto check_start = std::chrono::high_resolution_clock::now();
    if (d_voxel_keys_.size() != input_count)
    {
        std::cerr << "[ERROR] Voxel keys size mismatch: " << d_voxel_keys_.size()
                  << " vs " << input_count << std::endl;
        d_voxel_keys_.resize(input_count);
    }

    if (d_temp_points_.size() != input_count)
    {
        std::cerr << "[ERROR] Temp points size mismatch: " << d_temp_points_.size()
                  << " vs " << input_count << std::endl;
        return;
    }
    auto check_end = std::chrono::high_resolution_clock::now();
    float check_time = std::chrono::duration<float, std::milli>(check_end - check_start).count();

    // ========== Step 4: GPU Bucket Sort (å…¨GPUæµç¨‹) ==========
    auto sort_start = std::chrono::high_resolution_clock::now();

    const int NUM_BUCKETS = 1024;  // æ¡¶æ•°é‡

    // ç¡®ä¿ä¸´æ—¶ç¼“å†²åŒºå¤§å°è¶³å¤Ÿ
    if (d_bucket_indices_.size() < input_count)
    {
        d_bucket_indices_.resize(input_count);
    }
    if (d_temp_points_sort_.size() < input_count)
    {
        d_temp_points_sort_.resize(input_count);
    }
    if (d_temp_keys_sort_.size() < input_count)
    {
        d_temp_keys_sort_.resize(input_count);
    }
    if (d_bucket_counts_.size() < NUM_BUCKETS)
    {
        d_bucket_counts_.resize(NUM_BUCKETS);
    }
    if (d_bucket_offsets_.size() < NUM_BUCKETS)
    {
        d_bucket_offsets_.resize(NUM_BUCKETS);
    }
    if (d_bucket_positions_.size() < NUM_BUCKETS)
    {
        d_bucket_positions_.resize(NUM_BUCKETS);
    }
    if (d_min_max_keys_.size() < 2)
    {
        d_min_max_keys_.resize(2);
    }

    // Step A: èŒƒå›´åˆ†æ - è®¡ç®— min/max key
    // block å·²åœ¨å‰é¢å£°æ˜ï¼Œç›´æ¥ä½¿ç”¨
    dim3 grid_range((input_count + block.x - 1) / block.x);

    // åˆå§‹åŒ– min/max
    uint64_t init_min = UINT64_MAX;
    uint64_t init_max = 0;
    cudaMemcpyAsync(thrust::raw_pointer_cast(d_min_max_keys_.data()), &init_min, 
                    sizeof(uint64_t), cudaMemcpyHostToDevice, stream_);
    cudaMemcpyAsync(thrust::raw_pointer_cast(d_min_max_keys_.data()) + 1, &init_max, 
                    sizeof(uint64_t), cudaMemcpyHostToDevice, stream_);

    GPUBucketSort::analyzeKeyRangeKernel<<<grid_range, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_voxel_keys_.data()),
        static_cast<int>(input_count),
        thrust::raw_pointer_cast(d_min_max_keys_.data()),
        thrust::raw_pointer_cast(d_min_max_keys_.data()) + 1);

    // ä¸‹è½½ min/max (éœ€è¦åŒæ­¥ï¼Œå› ä¸ºåç»­æ­¥éª¤ä¾èµ–)
    cudaStreamSynchronize(stream_);
    uint64_t min_key, max_key;
    cudaMemcpy(&min_key, thrust::raw_pointer_cast(d_min_max_keys_.data()), 
               sizeof(uint64_t), cudaMemcpyDeviceToHost);
    cudaMemcpy(&max_key, thrust::raw_pointer_cast(d_min_max_keys_.data()) + 1, 
               sizeof(uint64_t), cudaMemcpyDeviceToHost);

    uint64_t key_range = (max_key > min_key) ? (max_key - min_key) : 1;

    // Step B: è®¡ç®—æ¡¶ç´¢å¼•
    dim3 grid_bucket((input_count + block.x - 1) / block.x);
    GPUBucketSort::computeBucketIndicesKernel<<<grid_bucket, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_voxel_keys_.data()),
        thrust::raw_pointer_cast(d_bucket_indices_.data()),
        static_cast<int>(input_count),
        min_key,
        key_range,
        NUM_BUCKETS);

    // Step C: ç»Ÿè®¡æ¡¶å¤§å°
    thrust::fill(thrust::cuda::par.on(stream_), 
                 d_bucket_counts_.begin(), d_bucket_counts_.begin() + NUM_BUCKETS, 0);

    dim3 grid_count((input_count + block.x - 1) / block.x);
    GPUBucketSort::countBucketSizesKernel<<<grid_count, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_bucket_indices_.data()),
        thrust::raw_pointer_cast(d_bucket_counts_.data()),
        static_cast<int>(input_count),
        NUM_BUCKETS);

    // Step D: å‰ç¼€å’Œæ‰«æè®¡ç®—æ¡¶åç§»é‡
    thrust::exclusive_scan(thrust::cuda::par.on(stream_),
                           d_bucket_counts_.begin(), 
                           d_bucket_counts_.begin() + NUM_BUCKETS,
                           d_bucket_offsets_.begin(),
                           0);

    // Step E: å…¨å±€é‡æ’ï¼ˆå…³é”®ä¼˜åŒ–ç‚¹ï¼Œæ¶ˆé™¤224ms CPUé‡æ’ï¼‰
    thrust::fill(thrust::cuda::par.on(stream_),
                 d_bucket_positions_.begin(), d_bucket_positions_.begin() + NUM_BUCKETS, 0);

    dim3 grid_distribute((input_count + block.x - 1) / block.x);
    GPUBucketSort::distributeToBucketsKernel<<<grid_distribute, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_temp_points_.data()),
        thrust::raw_pointer_cast(d_voxel_keys_.data()),
        thrust::raw_pointer_cast(d_bucket_indices_.data()),
        thrust::raw_pointer_cast(d_bucket_offsets_.data()),
        thrust::raw_pointer_cast(d_temp_points_sort_.data()),
        thrust::raw_pointer_cast(d_temp_keys_sort_.data()),
        thrust::raw_pointer_cast(d_bucket_positions_.data()),
        static_cast<int>(input_count));

    // äº¤æ¢ç¼“å†²åŒºï¼ˆä½¿ç”¨swapé¿å…æ‹·è´ï¼‰
    d_temp_points_.swap(d_temp_points_sort_);
    d_voxel_keys_.swap(d_temp_keys_sort_);

    // Step F: æ¡¶å†…ç²¾æ’ï¼ˆä½¿ç”¨åŸºæ•°æ’åºï¼‰
    dim3 grid_radix(NUM_BUCKETS, 1);  // æ¯ä¸ªæ¡¶ä¸€ä¸ªblock
    dim3 block_radix(32);  // æ¯ä¸ªblock 32ä¸ªçº¿ç¨‹ï¼ˆä¸€ä¸ªwarpï¼‰

    GPUBucketSort::radixSortWithinBucketsKernel<<<grid_radix, block_radix, 0, stream_>>>(
        thrust::raw_pointer_cast(d_temp_points_.data()),
        thrust::raw_pointer_cast(d_voxel_keys_.data()),
        thrust::raw_pointer_cast(d_temp_points_sort_.data()),
        thrust::raw_pointer_cast(d_temp_keys_sort_.data()),
        thrust::raw_pointer_cast(d_bucket_offsets_.data()),
        thrust::raw_pointer_cast(d_bucket_counts_.data()),
        NUM_BUCKETS);

    // æœ€ç»ˆäº¤æ¢å›æ’åºåçš„æ•°æ®
    d_temp_points_.swap(d_temp_points_sort_);
    d_voxel_keys_.swap(d_temp_keys_sort_);

    // ç¡®ä¿æ‰€æœ‰å¼‚æ­¥æ“ä½œå®Œæˆ
    cudaStreamSynchronize(stream_);

    // é”™è¯¯æ£€æŸ¥
    cudaError_t sort_error = cudaGetLastError();
    if (sort_error != cudaSuccess)
    {
        std::cerr << "[ERROR] GPU Bucket Sort failed: " << cudaGetErrorString(sort_error) << std::endl;
        return;
    }

    auto sort_end = std::chrono::high_resolution_clock::now();
    float sort_time = std::chrono::duration<float, std::milli>(sort_end - sort_start).count();

    // Step 5: åç»­å¤„ç†
    auto process_start = std::chrono::high_resolution_clock::now();
    // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å®é™…ç‚¹äº‘å¤§å°è€Œä¸æ˜¯åŸå§‹è¾“å…¥å¤§å°
    size_t actual_count = d_temp_points_.size();
    processVoxelCentroids(actual_count);
    auto process_end = std::chrono::high_resolution_clock::now();
    float process_time = std::chrono::duration<float, std::milli>(process_end - process_start).count();

    auto total_end = std::chrono::high_resolution_clock::now();
    float total_time = std::chrono::duration<float, std::milli>(total_end - total_start).count();

    std::cout << "[VoxelFilter] Timing breakdown:" << std::endl;
    std::cout << "  Memory setup: " << memory_time << " ms" << std::endl;
    std::cout << "  Kernel compute: " << kernel_time << " ms" << std::endl;
    std::cout << "  Size check: " << check_time << " ms" << std::endl;
    std::cout << "  GPU Bucket Sort: " << sort_time << " ms" << std::endl;
    std::cout << "  Process centroids: " << process_time << " ms" << std::endl;
    std::cout << "  Total: " << total_time << " ms" << std::endl;
}

//  åŸºæ•°æ’åºå®ç° - ä¸“é—¨ä¼˜åŒ–64ä½æ•´æ•°keys
void radixSort(std::vector<size_t> &indices, const std::vector<uint64_t> &keys)
{
    const size_t n = indices.size();
    if (n <= 1)
        return;

    std::vector<size_t> temp_indices(n);
    const int RADIX_BITS = 8;                                  // æ¯æ¬¡å¤„ç†8ä½
    const int RADIX_SIZE = 1 << RADIX_BITS;                    // 256
    const int NUM_PASSES = (64 + RADIX_BITS - 1) / RADIX_BITS; // 8æ¬¡éå†

    for (int pass = 0; pass < NUM_PASSES; ++pass)
    {
        // è®¡æ•°æ•°ç»„
        std::vector<int> count(RADIX_SIZE, 0);
        int shift = pass * RADIX_BITS;

        // ç»Ÿè®¡æ¯ä¸ªæ¡¶çš„å…ƒç´ æ•°é‡
        for (size_t i = 0; i < n; ++i)
        {
            int digit = (keys[indices[i]] >> shift) & (RADIX_SIZE - 1);
            count[digit]++;
        }

        // è½¬æ¢ä¸ºç´¯ç§¯è®¡æ•°
        for (int i = 1; i < RADIX_SIZE; ++i)
        {
            count[i] += count[i - 1];
        }

        // ä»åå¾€å‰åˆ†é…åˆ°ä¸´æ—¶æ•°ç»„
        for (int i = static_cast<int>(n) - 1; i >= 0; --i)
        {
            int digit = (keys[indices[i]] >> shift) & (RADIX_SIZE - 1);
            temp_indices[--count[digit]] = indices[i];
        }

        // å¤åˆ¶å›åŸæ•°ç»„
        indices = temp_indices;
    }
}

bool GPUPreprocessor::cpuFallbackSort(size_t input_count)
{
    auto cpu_total_start = std::chrono::high_resolution_clock::now();
    std::cout << "[INFO] Using CPU radix sort fallback..." << std::endl;

    try
    {
        // Step 1: ä¸‹è½½æ•°æ®åˆ°CPU
        auto download_start = std::chrono::high_resolution_clock::now();
        thrust::host_vector<GPUPoint3f> h_points = d_temp_points_;
        thrust::host_vector<uint64_t> h_keys = d_voxel_keys_;
        auto download_end = std::chrono::high_resolution_clock::now();
        float download_time = std::chrono::duration<float, std::milli>(download_end - download_start).count();

        // Step 2: åˆ›å»ºç´¢å¼•
        auto index_start = std::chrono::high_resolution_clock::now();
        std::vector<size_t> indices(input_count);
        std::iota(indices.begin(), indices.end(), 0);
        auto index_end = std::chrono::high_resolution_clock::now();
        float index_time = std::chrono::duration<float, std::milli>(index_end - index_start).count();

        // è°ƒè¯•ï¼šæ£€æŸ¥åŸå§‹keys
        std::vector<uint64_t> std_keys(h_keys.begin(), h_keys.end());
        std::cout << "[DEBUG] First 10 voxel keys: ";
        for (size_t i = 0; i < std::min(size_t(10), input_count); ++i)
        {
            std::cout << std_keys[i] << " ";
        }
        std::cout << std::endl;

        // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰keyséƒ½ç›¸åŒ
        uint64_t first_key = std_keys[0];
        bool all_same = true;
        for (size_t i = 1; i < input_count; ++i)
        {
            if (std_keys[i] != first_key)
            {
                all_same = false;
                break;
            }
        }
        std::cout << "[DEBUG] All keys same? " << (all_same ? "YES" : "NO") << std::endl;

        // Step 3: CPUåŸºæ•°æ’åº (ä¸“é—¨ä¼˜åŒ–64ä½keys)
        auto sort_start = std::chrono::high_resolution_clock::now();

        if (all_same)
        {
            std::cout << "[WARNING] All voxel keys are identical - skipping sort" << std::endl;
        }
        else
        {
            radixSort(indices, std_keys);
        }

        auto sort_end = std::chrono::high_resolution_clock::now();
        float sort_time = std::chrono::duration<float, std::milli>(sort_end - sort_start).count();

        //  è°ƒè¯•ï¼šæ£€æŸ¥æ’åºåçš„å‰å‡ ä¸ªç´¢å¼•
        std::cout << "[DEBUG] First 10 sorted indices: ";
        for (size_t i = 0; i < std::min(size_t(10), input_count); ++i)
        {
            std::cout << indices[i] << " ";
        }
        std::cout << std::endl; // Step 4: é‡æ–°æ’åˆ—æ•°æ®
        auto rearrange_start = std::chrono::high_resolution_clock::now();
        thrust::host_vector<GPUPoint3f> sorted_points(input_count);
        thrust::host_vector<uint64_t> sorted_keys(input_count);

        for (size_t i = 0; i < input_count; ++i)
        {
            sorted_points[i] = h_points[indices[i]];
            sorted_keys[i] = h_keys[indices[i]];
        }
        auto rearrange_end = std::chrono::high_resolution_clock::now();
        float rearrange_time = std::chrono::duration<float, std::milli>(rearrange_end - rearrange_start).count();

        // Step 5: ä¸Šä¼ å›GPU
        auto upload_start = std::chrono::high_resolution_clock::now();
        d_temp_points_ = sorted_points;
        d_voxel_keys_ = sorted_keys;
        auto upload_end = std::chrono::high_resolution_clock::now();
        float upload_time = std::chrono::duration<float, std::milli>(upload_end - upload_start).count();

        auto cpu_total_end = std::chrono::high_resolution_clock::now();
        float cpu_total_time = std::chrono::duration<float, std::milli>(cpu_total_end - cpu_total_start).count();

        std::cout << "[CPUSort] Detailed timing breakdown (Radix Sort):" << std::endl;
        std::cout << "  GPU->CPU download: " << download_time << " ms" << std::endl;
        std::cout << "  Index creation: " << index_time << " ms" << std::endl;
        std::cout << "  CPU radix sort: " << sort_time << " ms" << std::endl;
        std::cout << "  Data rearrange: " << rearrange_time << " ms" << std::endl;
        std::cout << "  CPU->GPU upload: " << upload_time << " ms" << std::endl;
        std::cout << "  CPU total: " << cpu_total_time << " ms" << std::endl;

        return true;
    }
    catch (const std::exception &e)
    {
        std::cerr << "[ERROR] CPU fallback sort failed: " << e.what() << std::endl;
        return false;
    }
}

// å°†åç»­å¤„ç†æ‹†åˆ†ä¸ºç‹¬ç«‹å‡½æ•°
void GPUPreprocessor::processVoxelCentroids(size_t input_count)
{
    //  è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥è¾“å…¥æ•°æ®
    std::cout << "[DEBUG] processVoxelCentroids input_count=" << input_count
              << ", d_temp_points_.size()=" << d_temp_points_.size()
              << ", d_voxel_keys_.size()=" << d_voxel_keys_.size() << std::endl;

    // ç¡®ä¿è¾“å…¥æ•°æ®ä¸€è‡´æ€§
    if (d_temp_points_.size() != input_count || d_voxel_keys_.size() != input_count)
    {
        std::cerr << "[ERROR] Size mismatch in processVoxelCentroids!" << std::endl;
        return;
    }

    // Step 3: è®¡ç®—ä½“ç´ è´¨å¿ƒ
    thrust::device_vector<int> d_point_counts(input_count);
    thrust::device_vector<int> d_ones(input_count, 1);

    d_unique_keys_.resize(input_count);
    thrust::device_vector<GPUPoint3f> d_temp_centroids(input_count);

    // reduce_by_keyè®¡ç®—
    auto count_end = thrust::reduce_by_key(
        d_voxel_keys_.begin(), d_voxel_keys_.begin() + input_count,
        d_ones.begin(),
        d_unique_keys_.begin(),
        d_point_counts.begin());

    auto sum_end = thrust::reduce_by_key(
        d_voxel_keys_.begin(), d_voxel_keys_.begin() + input_count,
        d_temp_points_.begin(),
        d_unique_keys_.begin(),
        d_temp_centroids.begin(),
        thrust::equal_to<uint64_t>(),
        [] __device__(const GPUPoint3f &a, const GPUPoint3f &b)
        {
            return GPUPoint3f{a.x + b.x, a.y + b.y, a.z + b.z};
        });

    size_t unique_count = count_end.second - d_point_counts.begin();

    std::cout << "Found " << unique_count << " unique voxels" << std::endl;

    if (unique_count == 0)
    {
        std::cerr << "[WARNING] No unique voxels found!" << std::endl;
        d_output_points_.clear();
        d_temp_points_.clear();
        return;
    }

    // Step 4: è®¡ç®—å¹³å‡å€¼
    thrust::transform(
        d_temp_centroids.begin(), d_temp_centroids.begin() + unique_count,
        d_point_counts.begin(),
        d_temp_centroids.begin(),
        [] __device__(const GPUPoint3f &sum_point, int count)
        {
            float inv_count = 1.0f / count;
            return GPUPoint3f{
                sum_point.x * inv_count,
                sum_point.y * inv_count,
                sum_point.z * inv_count};
        });

    // å®‰å…¨åœ°æ›´æ–°è¾“å‡º
    if (unique_count > 0)
    {
        thrust::host_vector<GPUPoint3f> h_result(unique_count);
        thrust::copy_n(d_temp_centroids.begin(), unique_count, h_result.begin());
        d_output_points_ = h_result;
        d_temp_points_ = d_output_points_;

        std::cout << "[GPUPreprocessor] Voxel filter: " << input_count
                  << " -> " << unique_count << " points" << std::endl;
    }
    else
    {
        d_output_points_.clear();
        d_temp_points_.clear();
    }
}

void GPUPreprocessor::cuda_launchOutlierRemoval(const PreprocessConfig &config)
{
    int point_count = getCurrentPointCount();
    if (point_count == 0)
    {
        std::cout << "[OutlierRemoval] No points to process" << std::endl;
        return;
    }

    std::cout << "[OutlierRemoval] Processing " << point_count << " points" << std::endl;
    std::cout << "[OutlierRemoval] Parameters: radius=" << config.radius_search
              << ", min_neighbors=" << config.min_radius_neighbors << std::endl;

    // å‚æ•°è®¡ç®— - é’ˆå¯¹ä½“ç´ ä¸‹é‡‡æ ·åçš„ç‚¹äº‘ä¼˜åŒ–å‚æ•°
    float grid_size = config.radius_search * 0.4f; // å‡å°ç½‘æ ¼å¤§å°ï¼Œæé«˜ç²¾åº¦
    int hash_table_size = point_count * 6;         // ğŸ”§ è¿›ä¸€æ­¥å¢å¤§å“ˆå¸Œè¡¨ï¼Œå‡å°‘å†²çª

    std::cout << "[OutlierRemoval] Grid size: " << grid_size
              << ", hash table size: " << hash_table_size << std::endl;

    // ç¡®ä¿ç¼“å†²åŒºå¤§å° (å¤ç”¨ç°æœ‰ç¼“å†²åŒº)
    d_voxel_keys_.resize(point_count);  // å¤ç”¨ä½œä¸ºpoint_hashes
    d_knn_indices_.resize(point_count); // å¤ç”¨ä½œä¸ºhash_entries
    // d_hash_table_.resize(hash_table_size);

    // ä¸´æ—¶æœ‰æ•ˆæ€§æ©ç 
    static thrust::device_vector<bool> d_valid_mask;
    d_valid_mask.resize(point_count);

    // ä¸´æ—¶è¾“å‡ºç¼“å†²åŒº
    static thrust::device_vector<GPUPoint3f> d_filtered_points;
    d_filtered_points.resize(point_count);

    // // è°ƒç”¨ç©ºé—´å“ˆå¸Œç¦»ç¾¤ç‚¹ç§»é™¤
    // int filtered_count = SpatialHashOutlier::launchSpatialHashOutlierRemoval(
    //     thrust::raw_pointer_cast(d_temp_points_.data()),    // è¾“å…¥
    //     thrust::raw_pointer_cast(d_filtered_points.data()), // è¾“å‡º
    //     thrust::raw_pointer_cast(d_valid_mask.data()),      // æ©ç 
    //     thrust::raw_pointer_cast(d_voxel_keys_.data()),     // å¤ç”¨å“ˆå¸Œ
    //     thrust::raw_pointer_cast(d_knn_indices_.data()),    // å¤ç”¨é“¾è¡¨
    //     thrust::raw_pointer_cast(d_hash_table_.data()),     // å“ˆå¸Œè¡¨
    //     point_count,
    //     config.radius_search,
    //     config.min_radius_neighbors,
    //     grid_size,
    //     hash_table_size);

    // // æ›´æ–°å·¥ä½œç‚¹äº‘
    // d_temp_points_.resize(filtered_count);
    // thrust::copy(d_filtered_points.begin(),
    //              d_filtered_points.begin() + filtered_count,
    //              d_temp_points_.begin());

    // std::cout << "[OutlierRemoval] Result: " << point_count << " -> " << filtered_count
    //           << " points (removed " << (point_count - filtered_count) << " outliers)" << std::endl;
}

void GPUPreprocessor::cuda_launchGroundRemoval(float threshold)
{
    std::cout << "[GPUPreprocessor] Starting ground removal" << std::endl;

    size_t input_count = d_temp_points_.size();
    if (input_count == 0)
        return;

    dim3 block(256);
    dim3 grid((input_count + block.x - 1) / block.x);

    // é‡ç”¨d_valid_flags_ä½œä¸ºground_flags
    GroundRemoval::ransacGroundDetectionKernel<<<grid, block, 0, stream_>>>(
        thrust::raw_pointer_cast(d_temp_points_.data()),
        thrust::raw_pointer_cast(d_valid_flags_.data()),
        input_count, threshold, 1000);
    cudaStreamSynchronize(stream_);

    // ç›´æ¥è¿‡æ»¤éåœ°é¢ç‚¹
    thrust::device_vector<GPUPoint3f> d_temp_result(input_count);

    auto new_end = thrust::copy_if(
        d_temp_points_.begin(), d_temp_points_.begin() + input_count,
        d_valid_flags_.begin(),
        d_temp_result.begin(),
        [] __device__(bool is_ground)
        { return !is_ground; });

    size_t output_count = new_end - d_temp_result.begin();

    // å®‰å…¨åœ°æ›´æ–°æˆå‘˜å˜é‡
    if (output_count > 0)
    {
        thrust::host_vector<GPUPoint3f> h_result(output_count);
        thrust::copy_n(d_temp_result.begin(), output_count, h_result.begin());
        d_output_points_ = h_result;
    }
    else
    {
        d_output_points_.clear();
    }

    d_temp_points_ = d_output_points_;

    std::cout << "[GPUPreprocessor] Ground removal: " << input_count << " -> " << output_count << " points" << std::endl;
}

void GPUPreprocessor::cuda_compactValidPoints()
{
    size_t input_count = d_temp_points_.size();
    if (input_count == 0)
        return;

    // ç›´æ¥ä½¿ç”¨thrust::copy_ifè¿›è¡Œå‹ç¼©
    thrust::device_vector<GPUPoint3f> d_temp_result(input_count);

    auto new_end = thrust::copy_if(
        d_temp_points_.begin(), d_temp_points_.begin() + input_count,
        d_valid_flags_.begin(),
        d_temp_result.begin(),
        thrust::identity<bool>());

    size_t output_count = new_end - d_temp_result.begin();

    // å®‰å…¨åœ°æ›´æ–°æˆå‘˜å˜é‡
    if (output_count > 0)
    {
        thrust::host_vector<GPUPoint3f> h_result(output_count);
        thrust::copy_n(d_temp_result.begin(), output_count, h_result.begin());
        d_output_points_ = h_result;
    }
    else
    {
        d_output_points_.clear();
    }

    d_temp_points_ = d_output_points_;
}

void GPUPreprocessor::cuda_prepareInputBuffer(size_t count)
{
    // åœ¨.cuæ–‡ä»¶ä¸­ï¼Œresizeæ˜¯å®‰å…¨çš„
    if (d_input_points_.size() < count)
    {
        d_input_points_.resize(count);
    }
}

void GPUPreprocessor::cuda_unpackROSMsg(
    const uint8_t* d_raw_data,
    GPUPoint3f* d_output_points,
    int point_step,
    int x_offset, int y_offset, int z_offset, int intensity_offset,
    uint8_t x_datatype, uint8_t y_datatype, uint8_t z_datatype, uint8_t intensity_datatype,
    size_t num_points
)
{
    if (num_points == 0 || d_raw_data == nullptr || d_output_points == nullptr)
        return;

    dim3 block(256);
    dim3 grid((num_points + block.x - 1) / block.x);
    
    unpackROSMsgKernel<<<grid, block, 0, stream_>>>(
        d_raw_data,
        d_output_points,
        point_step,
        x_offset, y_offset, z_offset, intensity_offset,
        x_datatype, y_datatype, z_datatype, intensity_datatype,
        num_points
    );
}

void GPUPreprocessor::cuda_uploadGPUPoints(const GPUPoint3f* h_pinned_points, size_t count)
{
    if (count == 0 || h_pinned_points == nullptr)
        return;

    if (stream_ == nullptr)
    {
        std::cerr << "[ERROR] CUDA stream not initialized" << std::endl;
        return;
    }

    auto start = std::chrono::high_resolution_clock::now();

    // ç¡®ä¿ d_input_points_ æœ‰è¶³å¤Ÿå®¹é‡
    if (d_input_points_.size() < count)
    {
        d_input_points_.resize(count);
    }

    // ğŸ”¥ å…³é”®ï¼šä½¿ç”¨å¼‚æ­¥ä¸Šä¼ å’Œ pinned memoryï¼ˆDMAç›´æ¥è®¿é—®ï¼Œé¿å…é©±åŠ¨å±‚æ‹·è´ï¼‰
    cudaError_t err = cudaMemcpyAsync(
        thrust::raw_pointer_cast(d_input_points_.data()), // é¢„åˆ†é…çš„GPUç©ºé—´
        h_pinned_points,                                  // CPUæºï¼ˆpinned memoryï¼‰
        count * sizeof(GPUPoint3f),                        // å­—èŠ‚æ•°
        cudaMemcpyHostToDevice,                            // ä¼ è¾“æ–¹å‘
        stream_                                            // ç»‘å®šåˆ°stream
    );
    if (err != cudaSuccess)
    {
        std::cerr << "[ERROR] cudaMemcpyAsync failed: " << cudaGetErrorString(err) << std::endl;
        return;
    }

    // ğŸš€ GPUå†…éƒ¨æ‹·è´ï¼ˆè¶…å¿«ï¼Œå¼‚æ­¥ï¼‰
    if (d_temp_points_.size() < count)
    {
        d_temp_points_.resize(count);
    }
    err = cudaMemcpyAsync(
        thrust::raw_pointer_cast(d_temp_points_.data()),
        thrust::raw_pointer_cast(d_input_points_.data()),
        count * sizeof(GPUPoint3f),
        cudaMemcpyDeviceToDevice,
        stream_  // ç»‘å®šåˆ°stream
    );
    if (err != cudaSuccess)
    {
        std::cerr << "[ERROR] GPU internal copy failed: " << cudaGetErrorString(err) << std::endl;
        return;
    }

    // ğŸ”§ å…³é”®ä¿®å¤ï¼šæ­£ç¡®è®¾ç½®d_temp_points_çš„é€»è¾‘å¤§å°
    d_temp_points_.resize(count);

    // ç§»é™¤åŒæ­¥ï¼šä¿æŒå¼‚æ­¥ï¼Œç”±è°ƒç”¨è€…å†³å®šä½•æ—¶åŒæ­¥
    // cudaStreamSynchronize(stream_);  // ä»…åœ¨å¿…è¦æ—¶åŒæ­¥

    auto end = std::chrono::high_resolution_clock::now();
    float upload_time = std::chrono::duration<float, std::milli>(end - start).count();

    std::cout << "[GPUPreprocessor] âš¡ ASYNC upload: " << count
              << " points in " << upload_time << " ms (pinned memory + async)" << std::endl;
}

void GPUPreprocessor::convertToPointsWithNormals()
{
    size_t point_count = d_temp_points_.size();
    if (point_count == 0)
        return;

    //  åœ¨ .cu æ–‡ä»¶ä¸­ï¼Œresize åº”è¯¥å·¥ä½œæ­£å¸¸
    d_output_points_normal_.clear();
    d_output_points_normal_.resize(point_count);

    cuda_convertToPointsWithNormals(
        thrust::raw_pointer_cast(d_temp_points_.data()),
        thrust::raw_pointer_cast(d_output_points_normal_.data()),
        point_count);
}
void GPUPreprocessor::reserveMemory(size_t max_points)
{
    // ä½¿ç”¨resize()è€Œä¸æ˜¯reserve()æ¥é¢„åˆ†é…å†…å­˜
    d_input_points_.resize(max_points);
    d_temp_points_.resize(max_points);
    d_output_points_.resize(max_points);
    d_output_points_normal_.resize(max_points);
    d_voxel_keys_.resize(max_points);
    d_valid_flags_.resize(max_points);
    // d_radix_temp_points_.resize(max_points);
    // d_radix_temp_keys_.resize(max_points);

    std::cout << "[GPUPreprocessor] Pre-allocated memory for " << max_points << " points" << std::endl;
}

void GPUPreprocessor::clearMemory()
{
    d_input_points_.clear();
    d_temp_points_.clear();
    d_output_points_.clear();
    d_output_points_normal_.clear();
    d_voxel_keys_.clear();
    d_voxel_boundaries_.clear();
    d_unique_keys_.clear();
    d_neighbor_counts_.clear();
    d_valid_flags_.clear();
    d_knn_indices_.clear();
    d_knn_distances_.clear();

    d_input_points_.shrink_to_fit();
    d_temp_points_.shrink_to_fit();
    d_output_points_.shrink_to_fit();
    d_output_points_normal_.shrink_to_fit();
}

// æ·»åŠ åˆ°ç°æœ‰ .cu æ–‡ä»¶ä¸­ï¼š

namespace SpatialHashNormals
{

    __device__ inline uint64_t computeSpatialHash(float x, float y, float z, float grid_size)
    {
        int gx = floorf(x / grid_size);
        int gy = floorf(y / grid_size);
        int gz = floorf(z / grid_size);

        // ä¿®å¤ï¼šä½¿ç”¨æ›´å¤§çš„å¯¹ç§°åç§»
        const uint64_t OFFSET = 0x80000000ULL; // 2^31ï¼Œç¡®ä¿æ­£è´Ÿå¯¹ç§°

        uint64_t ux = (uint64_t)(gx + OFFSET);
        uint64_t uy = (uint64_t)(gy + OFFSET);
        uint64_t uz = (uint64_t)(gz + OFFSET);

        // ä½¿ç”¨æ›´å¥½çš„å“ˆå¸Œæ··åˆ
        uint64_t hash = ux * 73856093ULL ^ uy * 19349663ULL ^ uz * 83492791ULL;

        // é¢å¤–çš„æ··åˆæ­¥éª¤ï¼Œç¡®ä¿å‡åŒ€åˆ†å¸ƒ
        hash ^= hash >> 32;
        hash *= 0x9e3779b97f4a7c15ULL;
        hash ^= hash >> 32;

        return hash;
    }

    // æ„å»ºç©ºé—´å“ˆå¸Œè¡¨
    __global__ void buildSpatialHashKernel(
        const GPUPoint3f *points,
        uint64_t *point_hashes,
        int *hash_table,
        int *hash_entries,
        int num_points,
        float grid_size,
        int hash_table_size)
    {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= num_points)
            return;

        // è®¡ç®—è¯¥ç‚¹çš„å“ˆå¸Œå€¼
        GPUPoint3f pt = points[idx];
        uint64_t hash = computeSpatialHash(pt.x, pt.y, pt.z, grid_size);
        point_hashes[idx] = hash;

        // æ’å…¥å“ˆå¸Œè¡¨ (é“¾è¡¨å¤´æ’æ³•)
        int hash_slot = hash % hash_table_size;
        int old_head = atomicExch(&hash_table[hash_slot], idx);
        hash_entries[idx] = old_head; // hash_entries[i] = ä¸‹ä¸€ä¸ªç‚¹çš„ç´¢å¼•
    }

    // åœ¨å“ˆå¸Œç½‘æ ¼ä¸­æœç´¢é‚»å±…
    __device__ inline void searchHashGrid(
        const GPUPoint3f &query_point,
        const GPUPoint3f *all_points,
        const uint64_t *point_hashes,
        const int *hash_table,
        const int *hash_entries,
        int *neighbors,
        float *distances,
        int *neighbor_count,
        float search_radius,
        float grid_size,
        int hash_table_size,
        int max_neighbors)
    {
        float radius_sq = search_radius * search_radius;
        int found = 0;

        // ğŸ”§ ä¿®å¤æœç´¢ç½‘æ ¼è®¡ç®—ï¼Œç¡®ä¿ä¸å“ˆå¸Œè®¡ç®—ä¸€è‡´
        int base_gx = floorf(query_point.x / grid_size);
        int base_gy = floorf(query_point.y / grid_size);
        int base_gz = floorf(query_point.z / grid_size);

        for (int dx = -1; dx <= 1; dx++)
        {
            for (int dy = -1; dy <= 1; dy++)
            {
                for (int dz = -1; dz <= 1; dz++)
                {
                    // å…³é”®ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ç½‘æ ¼ç´¢å¼•è®¡ç®—å“ˆå¸Œï¼Œä¸å†é€šè¿‡åæ ‡è½¬æ¢
                    int grid_gx = base_gx + dx;
                    int grid_gy = base_gy + dy;
                    int grid_gz = base_gz + dz;

                    // æ–°çš„å“ˆå¸Œç®—æ³•ï¼šä¸computeSpatialHashå®Œå…¨ä¸€è‡´
                    const uint64_t OFFSET = 0x80000000ULL; // 2^31ï¼Œç¡®ä¿æ­£è´Ÿå¯¹ç§°

                    uint64_t ux = (uint64_t)(grid_gx + OFFSET);
                    uint64_t uy = (uint64_t)(grid_gy + OFFSET);
                    uint64_t uz = (uint64_t)(grid_gz + OFFSET);

                    // ä½¿ç”¨æ›´å¥½çš„å“ˆå¸Œæ··åˆ
                    uint64_t grid_hash = ux * 73856093ULL ^ uy * 19349663ULL ^ uz * 83492791ULL;

                    // é¢å¤–çš„æ··åˆæ­¥éª¤ï¼Œç¡®ä¿å‡åŒ€åˆ†å¸ƒ
                    grid_hash ^= grid_hash >> 32;
                    grid_hash *= 0x9e3779b97f4a7c15ULL;
                    grid_hash ^= grid_hash >> 32;

                    int hash_slot = grid_hash % hash_table_size;
                    int current = hash_table[hash_slot];

                    // éå†è¯¥ç½‘æ ¼çš„é“¾è¡¨
                    while (current != -1 && found < max_neighbors)
                    {
                        GPUPoint3f candidate = all_points[current];

                        float dx_f = candidate.x - query_point.x;
                        float dy_f = candidate.y - query_point.y;
                        float dz_f = candidate.z - query_point.z;
                        float dist_sq = dx_f * dx_f + dy_f * dy_f + dz_f * dz_f;

                        if (dist_sq <= radius_sq && dist_sq > 0)
                        { // æ’é™¤è‡ªå·±
                            neighbors[found] = current;
                            distances[found] = sqrtf(dist_sq);
                            found++;
                        }

                        current = hash_entries[current];
                    }
                }
            }
        }

        *neighbor_count = found;
    }

    __device__ inline void fastEigen3x3(float cov[6], float *normal, float *curvature)
    {
        // å¯¹äº3x3å¯¹ç§°çŸ©é˜µï¼Œä½¿ç”¨å‰ç§¯æ–¹æ³•æ±‚æœ€å°ç‰¹å¾å‘é‡ï¼ˆæœ€ç¨³å®šï¼‰
        // cov[0]=xx, cov[1]=yy, cov[2]=zz, cov[3]=xy, cov[4]=xz, cov[5]=yz

        // æ„é€ çŸ©é˜µçš„ä¸‰è¡Œ
        float row0[3] = {cov[0], cov[3], cov[4]}; // [xx, xy, xz]
        float row1[3] = {cov[3], cov[1], cov[5]}; // [xy, yy, yz]
        float row2[3] = {cov[4], cov[5], cov[2]}; // [xz, yz, zz]

        // å°è¯•ä¸‰ç§ä¸åŒçš„å‰ç§¯ç»„åˆï¼Œé€‰æ‹©æœ€å¤§çš„
        float cross01[3], cross02[3], cross12[3];

        // row0 Ã— row1
        cross01[0] = row0[1] * row1[2] - row0[2] * row1[1];
        cross01[1] = row0[2] * row1[0] - row0[0] * row1[2];
        cross01[2] = row0[0] * row1[1] - row0[1] * row1[0];
        float norm01 = sqrtf(cross01[0] * cross01[0] + cross01[1] * cross01[1] + cross01[2] * cross01[2]);

        // row0 Ã— row2
        cross02[0] = row0[1] * row2[2] - row0[2] * row2[1];
        cross02[1] = row0[2] * row2[0] - row0[0] * row2[2];
        cross02[2] = row0[0] * row2[1] - row0[1] * row2[0];
        float norm02 = sqrtf(cross02[0] * cross02[0] + cross02[1] * cross02[1] + cross02[2] * cross02[2]);

        // row1 Ã— row2
        cross12[0] = row1[1] * row2[2] - row1[2] * row2[1];
        cross12[1] = row1[2] * row2[0] - row1[0] * row2[2];
        cross12[2] = row1[0] * row2[1] - row1[1] * row2[0];
        float norm12 = sqrtf(cross12[0] * cross12[0] + cross12[1] * cross12[1] + cross12[2] * cross12[2]);

        // é€‰æ‹©æ¨¡é•¿æœ€å¤§çš„å‰ç§¯ç»“æœï¼ˆæœ€ç¨³å®šï¼‰
        if (norm01 >= norm02 && norm01 >= norm12 && norm01 > 1e-8f)
        {
            normal[0] = cross01[0] / norm01;
            normal[1] = cross01[1] / norm01;
            normal[2] = cross01[2] / norm01;
        }
        else if (norm02 >= norm12 && norm02 > 1e-8f)
        {
            normal[0] = cross02[0] / norm02;
            normal[1] = cross02[1] / norm02;
            normal[2] = cross02[2] / norm02;
        }
        else if (norm12 > 1e-8f)
        {
            normal[0] = cross12[0] / norm12;
            normal[1] = cross12[1] / norm12;
            normal[2] = cross12[2] / norm12;
        }
        else
        {
            // æç«¯é€€åŒ–æƒ…å†µï¼šçŸ©é˜µå‡ ä¹æ˜¯å¥‡å¼‚çš„
            // ä½¿ç”¨å¯¹è§’å…ƒç´ æœ€å°çš„æ–¹å‘ä½œä¸ºæ³•çº¿
            if (cov[0] <= cov[1] && cov[0] <= cov[2])
            {
                normal[0] = 1.0f;
                normal[1] = 0.0f;
                normal[2] = 0.0f;
            }
            else if (cov[1] <= cov[2])
            {
                normal[0] = 0.0f;
                normal[1] = 1.0f;
                normal[2] = 0.0f;
            }
            else
            {
                normal[0] = 0.0f;
                normal[1] = 0.0f;
                normal[2] = 1.0f;
            }
        }

        // è®¡ç®—æ›²ç‡ï¼ˆæœ€å°ç‰¹å¾å€¼ä¼°è®¡ï¼‰
        float trace = cov[0] + cov[1] + cov[2];
        float min_eigenvalue = normal[0] * (cov[0] * normal[0] + cov[3] * normal[1] + cov[4] * normal[2]) +
                               normal[1] * (cov[3] * normal[0] + cov[1] * normal[1] + cov[5] * normal[2]) +
                               normal[2] * (cov[4] * normal[0] + cov[5] * normal[1] + cov[2] * normal[2]);
        *curvature = (trace > 1e-8f) ? fabsf(min_eigenvalue) / trace : 0.0f;
    }

    // ç©ºé—´å“ˆå¸Œæ³•çº¿ä¼°è®¡ä¸»kernel
    __global__ void spatialHashNormalsKernel(
        const GPUPoint3f *points,
        const uint64_t *point_hashes,
        const int *hash_table,
        const int *hash_entries,
        GPUPointNormal3f *points_with_normals,
        int num_points,
        float search_radius,
        int min_neighbors,
        float grid_size,
        int hash_table_size)
    {
        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= num_points)
            return;

        GPUPoint3f query_point = points[idx];

        // æœç´¢é‚»å±…
        int neighbors[64]; // æœ€å¤š64ä¸ªé‚»å±…
        float distances[64];
        int neighbor_count = 0;

        searchHashGrid(query_point, points, point_hashes, hash_table, hash_entries,
                       neighbors, distances, &neighbor_count,
                       search_radius, grid_size, hash_table_size, 64);

        //  è‡ªé€‚åº”é‚»å±…æœç´¢ä¼˜åŒ–
        // åœ¨æœç´¢é‚»å±…åï¼Œæ ¹æ®å®é™…æ‰¾åˆ°çš„é‚»å±…æ•°é‡è°ƒæ•´
        if (neighbor_count < min_neighbors)
        {
            // é‚»å±…ä¸è¶³æ—¶ï¼Œæ‰©å¤§æœç´¢åŠå¾„ (ä»…å¯¹å½“å‰ç‚¹)
            float extended_radius = search_radius * 1.5f;

            // é‡æ–°æœç´¢ (åªå¯¹å°‘æ•°ç‚¹æ‰§è¡Œï¼Œä¸å½±å“æ•´ä½“æ€§èƒ½)
            searchHashGrid(query_point, points, point_hashes, hash_table, hash_entries,
                           neighbors, distances, &neighbor_count,
                           extended_radius, grid_size, hash_table_size, 64);
        }

        // å¦‚æœé‚»å±…è¿‡å¤šï¼Œé€‰æ‹©æœ€è¿‘çš„é‚»å±…
        if (neighbor_count > 32)
        {
            // ç®€å•çš„éƒ¨åˆ†æ’åºï¼Œåªä¿ç•™æœ€è¿‘çš„32ä¸ª
            for (int i = 0; i < 32; i++)
            {
                for (int j = i + 1; j < neighbor_count; j++)
                {
                    if (distances[j] < distances[i])
                    {
                        // äº¤æ¢
                        float temp_dist = distances[i];
                        distances[i] = distances[j];
                        distances[j] = temp_dist;

                        int temp_idx = neighbors[i];
                        neighbors[i] = neighbors[j];
                        neighbors[j] = temp_idx;
                    }
                }
            }
            neighbor_count = 32; // åªä½¿ç”¨æœ€è¿‘çš„32ä¸ª
        }

        // å¤åˆ¶ç‚¹åæ ‡
        points_with_normals[idx].x = query_point.x;
        points_with_normals[idx].y = query_point.y;
        points_with_normals[idx].z = query_point.z;

        if (neighbor_count < min_neighbors)
        {
            // å³ä½¿æ‰©å¤§æœç´¢åä»ç„¶é‚»å±…ä¸è¶³ï¼Œè®¾ä¸ºæ— æ•ˆæ³•çº¿
            points_with_normals[idx].normal_x = 0.0f;
            points_with_normals[idx].normal_y = 0.0f;
            points_with_normals[idx].normal_z = 0.0f; // è®¾ä¸º0è¡¨ç¤ºæ— æ•ˆ
            return;
        }

        // è®¡ç®—è´¨å¿ƒ
        float cx = 0, cy = 0, cz = 0;
        for (int i = 0; i < neighbor_count; i++)
        {
            GPUPoint3f neighbor = points[neighbors[i]];
            cx += neighbor.x;
            cy += neighbor.y;
            cz += neighbor.z;
        }
        cx /= neighbor_count;
        cy /= neighbor_count;
        cz /= neighbor_count;

        // è®¡ç®—åæ–¹å·®çŸ©é˜µ
        float cov[6] = {0}; // xx, yy, zz, xy, xz, yz
        for (int i = 0; i < neighbor_count; i++)
        {
            GPUPoint3f neighbor = points[neighbors[i]];
            float dx = neighbor.x - cx;
            float dy = neighbor.y - cy;
            float dz = neighbor.z - cz;

            cov[0] += dx * dx; // xx
            cov[1] += dy * dy; // yy
            cov[2] += dz * dz; // zz
            cov[3] += dx * dy; // xy
            cov[4] += dx * dz; // xz
            cov[5] += dy * dz; // yz
        }

        // è®¡ç®—æ³•çº¿
        float normal[3];
        float curvature;
        fastEigen3x3(cov, normal, &curvature);

        // å¯¹äºæ¤­çƒç­‰å‡ ä½•ä½“ï¼Œä¸å¼ºåˆ¶æ³•çº¿æ–¹å‘ç»Ÿä¸€
        // æ³•çº¿æ–¹å‘åº”è¯¥ç”±å‡ ä½•å½¢çŠ¶æœ¬èº«å†³å®š
        // è¿™é‡Œå¯ä»¥é€‰æ‹©æ€§åœ°æ ¹æ®å‡ ä½•ç‰¹æ€§è°ƒæ•´æ–¹å‘ï¼Œä½†ä¸å¼ºåˆ¶z>0

        // è¾“å‡ºç»“æœ
        points_with_normals[idx].normal_x = normal[0];
        points_with_normals[idx].normal_y = normal[1];
        points_with_normals[idx].normal_z = normal[2];
    }

} // namespace SpatialHashNormals

// void GPUPreprocessor::launchNormalEstimation(float normal_radius, int normal_k)
// {
//     int point_count = getCurrentPointCount();
//     if (point_count == 0)
//         return;

//     // å‚æ•°è®¾ç½®
//     float grid_size = normal_radius * 0.5f;   // ç½‘æ ¼å¤§å°ä¸ºæœç´¢åŠå¾„çš„ä¸€åŠ
//     int hash_table_size = point_count * 4;    // å¢å¤§å“ˆå¸Œè¡¨ï¼Œå‡å°‘å†²çª
//     int min_neighbors = max(2, normal_k / 6); // é™ä½æœ€å°‘é‚»å±…æ•°è¦æ±‚ï¼Œä» k/3 æ”¹ä¸º k/6

//     // å¤ç”¨ç°æœ‰ç¼“å†²åŒº
//     d_voxel_keys_.resize(point_count);  // å¤ç”¨ä½œä¸ºpoint_hashes
//     d_knn_indices_.resize(point_count); // å¤ç”¨ä½œä¸ºhash_entries

//     // æ–°åˆ†é…å“ˆå¸Œè¡¨
//     // if (d_hash_table_.size() != hash_table_size)
//     // {
//     //     d_hash_table_.resize(hash_table_size);
//     // }

//     // åˆå§‹åŒ–å“ˆå¸Œè¡¨ä¸º-1
//     // thrust::fill(d_hash_table_.begin(), d_hash_table_.end(), -1);

//     // ç¡®ä¿è¾“å‡ºç¼“å†²åŒºè¶³å¤Ÿå¤§
//     d_output_points_normal_.resize(point_count);

//     // å¯åŠ¨kernel
//     dim3 block(256);
//     dim3 grid((point_count + block.x - 1) / block.x);

//     // Step 1: æ„å»ºç©ºé—´å“ˆå¸Œè¡¨
//     SpatialHashNormals::buildSpatialHashKernel<<<grid, block>>>(
//         thrust::raw_pointer_cast(d_temp_points_.data()),
//         thrust::raw_pointer_cast(d_voxel_keys_.data()), // å¤ç”¨
//         thrust::raw_pointer_cast(d_hash_table_.data()),
//         thrust::raw_pointer_cast(d_knn_indices_.data()), // å¤ç”¨
//         point_count,
//         grid_size,
//         hash_table_size);

//     cudaDeviceSynchronize(); // ç¡®ä¿å“ˆå¸Œè¡¨æ„å»ºå®Œæˆ

//     // Step 2: æœç´¢é‚»å±…å¹¶è®¡ç®—æ³•çº¿
//     SpatialHashNormals::spatialHashNormalsKernel<<<grid, block>>>(
//         thrust::raw_pointer_cast(d_temp_points_.data()),
//         thrust::raw_pointer_cast(d_voxel_keys_.data()), // point_hashes
//         thrust::raw_pointer_cast(d_hash_table_.data()),
//         thrust::raw_pointer_cast(d_knn_indices_.data()), // hash_entries
//         thrust::raw_pointer_cast(d_output_points_normal_.data()),
//         point_count,
//         normal_radius,
//         min_neighbors,
//         grid_size,
//         hash_table_size);

//     cudaDeviceSynchronize();
// }

// namespace SpatialHashOutlier
// {

//     // å¤ç”¨æ³•çº¿ä¼°è®¡çš„å®Œæ•´ç©ºé—´å“ˆå¸ŒåŸºç¡€è®¾æ–½
//     // æ³¨æ„: å®Œå…¨ä¾èµ– SpatialHashNormals å‘½åç©ºé—´ï¼Œä¸é‡å¤å®ç°

//     // ç¦»ç¾¤ç‚¹æ£€æµ‹kernel - å®Œå…¨å¤ç”¨æ³•çº¿ä¼°è®¡çš„é‚»å±…æœç´¢åŸºç¡€è®¾æ–½
//     __global__ void spatialHashOutlierKernel(
//         const GPUPoint3f *input_points,
//         bool *is_valid,
//         const uint64_t *point_hashes,
//         const int *hash_table,
//         const int *hash_entries,
//         int num_points,
//         float search_radius,
//         int min_neighbors_threshold,
//         float grid_size,
//         int hash_table_size)
//     {
//         int idx = blockIdx.x * blockDim.x + threadIdx.x;
//         if (idx >= num_points)
//             return;

//         GPUPoint3f query_point = input_points[idx];

//         // å®Œå…¨å¤ç”¨æ³•çº¿ä¼°è®¡çš„é‚»å±…æœç´¢ç®—æ³•
//         int neighbors[32]; // ç¦»ç¾¤ç‚¹æ£€æµ‹ä¸éœ€è¦å¤ªå¤šé‚»å±…ï¼Œ32ä¸ªè¶³å¤Ÿ
//         float distances[32];
//         int neighbor_count = 0;

//         // ç›´æ¥è°ƒç”¨æ³•çº¿ä¼°è®¡çš„searchHashGridå‡½æ•°
//         SpatialHashNormals::searchHashGrid(
//             query_point, input_points, point_hashes, hash_table, hash_entries,
//             neighbors, distances, &neighbor_count,
//             search_radius, grid_size, hash_table_size, 32);

//         // ç®€å•çš„é‚»å±…æ•°é‡é˜ˆå€¼åˆ¤æ–­
//         is_valid[idx] = (neighbor_count >= min_neighbors_threshold);
//     }

//     // é«˜åº¦ä¼˜åŒ–çš„ç¦»ç¾¤ç‚¹ç§»é™¤ä¸»å‡½æ•° - å®Œå…¨å¤ç”¨æ³•çº¿ä¼°è®¡åŸºç¡€è®¾æ–½
//     int launchSpatialHashOutlierRemoval(
//         const GPUPoint3f *d_input_points,
//         GPUPoint3f *d_output_points,
//         bool *d_valid_mask,
//         uint64_t *d_point_hashes, // å¤ç”¨æ³•çº¿ä¼°è®¡çš„å“ˆå¸Œç¼“å†²åŒº
//         int *d_hash_entries,      // å¤ç”¨æ³•çº¿ä¼°è®¡çš„é“¾è¡¨ç¼“å†²åŒº
//         int *d_hash_table,
//         int point_count,
//         float outlier_radius,
//         int min_neighbors_threshold,
//         float grid_size,
//         int hash_table_size)
//     {
//         if (point_count == 0)
//             return 0;

//         // Step 1: ç›´æ¥å¤ç”¨æ³•çº¿ä¼°è®¡çš„å“ˆå¸Œæ„å»ºå‡½æ•°
//         // æ¸…ç©ºå“ˆå¸Œè¡¨
//         cudaMemset(d_hash_table, -1, hash_table_size * sizeof(int));

//         dim3 block(256);
//         dim3 grid((point_count + block.x - 1) / block.x);

//         // ç›´æ¥è°ƒç”¨æ³•çº¿ä¼°è®¡çš„buildSpatialHashKernel
//         SpatialHashNormals::buildSpatialHashKernel<<<grid, block>>>(
//             d_input_points, d_point_hashes, d_hash_table, d_hash_entries,
//             point_count, grid_size, hash_table_size);

//         cudaDeviceSynchronize();

//         // Step 2: æ‰§è¡Œç¦»ç¾¤ç‚¹æ£€æµ‹ (å¤ç”¨æœç´¢ç®—æ³•)
//         spatialHashOutlierKernel<<<grid, block>>>(
//             d_input_points, d_valid_mask, d_point_hashes, d_hash_table, d_hash_entries,
//             point_count, outlier_radius, min_neighbors_threshold, grid_size, hash_table_size);

//         cudaDeviceSynchronize();

//         // Step 3: å‹ç¼©æ•°ç»„ï¼Œç§»é™¤ç¦»ç¾¤ç‚¹
//         auto end_it = thrust::copy_if(
//             thrust::device,
//             d_input_points,
//             d_input_points + point_count,
//             d_valid_mask,
//             d_output_points,
//             [] __device__(bool valid)
//             { return valid; });

//         return end_it - d_output_points;
//     }

// } // namespace SpatialHashOutlier

// æ¡¶æ’åºä»£æ›¿
namespace GPUBucketSort
{

    // Step 1: åˆ†ækeyåˆ†å¸ƒï¼Œç¡®å®šæ¡¶çš„èŒƒå›´
    __global__ void analyzeKeyRangeKernel(
        const uint64_t *keys,
        int count,
        uint64_t *min_key,
        uint64_t *max_key)
    {

        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= count)
            return;

        // ä½¿ç”¨block-level reductionæ‰¾min/max
        __shared__ uint64_t smin[256], smax[256];

        smin[threadIdx.x] = (idx < count) ? keys[idx] : UINT64_MAX;
        smax[threadIdx.x] = (idx < count) ? keys[idx] : 0;

        __syncthreads();

        // Reduction in shared memory
        for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)
        {
            if (threadIdx.x < stride)
            {
                smin[threadIdx.x] = min(smin[threadIdx.x], smin[threadIdx.x + stride]);
                smax[threadIdx.x] = max(smax[threadIdx.x], smax[threadIdx.x + stride]);
            }
            __syncthreads();
        }

        if (threadIdx.x == 0)
        {
            atomicMin((unsigned long long *)min_key, (unsigned long long)smin[0]);
            atomicMax((unsigned long long *)max_key, (unsigned long long)smax[0]);
        }
    }

    // Step 2: è®¡ç®—æ¯ä¸ªç‚¹å±äºå“ªä¸ªæ¡¶
    __global__ void computeBucketIndicesKernel(
        const uint64_t *keys,
        int *bucket_indices,
        int count,
        uint64_t min_key,
        uint64_t key_range,
        int num_buckets)
    {

        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= count)
            return;

        uint64_t key = keys[idx];
        uint64_t normalized_key = key - min_key;

        // é¿å…é™¤æ³•ï¼Œä½¿ç”¨ä½è¿ç®—ï¼ˆå¦‚æœnum_bucketsæ˜¯2çš„å¹‚ï¼‰
        int bucket_id = (int)((normalized_key * num_buckets) / (key_range + 1));
        bucket_id = min(bucket_id, num_buckets - 1); // ç¡®ä¿ä¸è¶Šç•Œ

        bucket_indices[idx] = bucket_id;
    }

    // Step 3: ç»Ÿè®¡æ¯ä¸ªæ¡¶çš„å¤§å°
    __global__ void countBucketSizesKernel(
        const int *bucket_indices,
        int *bucket_counts,
        int count,
        int num_buckets)
    {

        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= count)
            return;

        int bucket_id = bucket_indices[idx];
        atomicAdd(&bucket_counts[bucket_id], 1);
    }

    // Step 4: è®¡ç®—æ¯ä¸ªæ¡¶çš„èµ·å§‹ä½ç½®ï¼ˆprefix sumï¼‰
    __global__ void computeBucketOffsetsKernel(
        const int *bucket_counts,
        int *bucket_offsets,
        int num_buckets)
    {

        // ç®€å•çš„sequential prefix sum (å¯ä»¥ä¼˜åŒ–ä¸ºå¹¶è¡Œ)
        if (blockIdx.x == 0 && threadIdx.x == 0)
        {
            bucket_offsets[0] = 0;
            for (int i = 1; i < num_buckets; i++)
            {
                bucket_offsets[i] = bucket_offsets[i - 1] + bucket_counts[i - 1];
            }
        }
    }

    // Step 5: å°†æ•°æ®åˆ†é…åˆ°å„ä¸ªæ¡¶
    __global__ void distributeToBucketsKernel(
        const GPUPoint3f *input_points,
        const uint64_t *input_keys,
        const int *bucket_indices,
        const int *bucket_offsets,
        GPUPoint3f *output_points,
        uint64_t *output_keys,
        int *bucket_positions, // æ¯ä¸ªæ¡¶å½“å‰ä½ç½®çš„åŸå­è®¡æ•°å™¨
        int count)
    {

        int idx = blockIdx.x * blockDim.x + threadIdx.x;
        if (idx >= count)
            return;

        int bucket_id = bucket_indices[idx];
        int pos = atomicAdd(&bucket_positions[bucket_id], 1);
        int output_idx = bucket_offsets[bucket_id] + pos;

        output_points[output_idx] = input_points[idx];
        output_keys[output_idx] = input_keys[idx];
    }

    // Step 6: å¯¹æ¯ä¸ªæ¡¶å†…éƒ¨æ’åºï¼ˆä½¿ç”¨ç®€å•çš„å¹¶è¡Œæ’å…¥æ’åºï¼‰
    __global__ void sortWithinBucketsKernel(
        GPUPoint3f *points,
        uint64_t *keys,
        const int *bucket_offsets,
        const int *bucket_counts,
        int num_buckets)
    {

        int bucket_id = blockIdx.x * blockDim.x + threadIdx.x;
        if (bucket_id >= num_buckets)
            return;

        int start = bucket_offsets[bucket_id];
        int size = bucket_counts[bucket_id];

        if (size <= 1)
            return;

        // å•çº¿ç¨‹å¯¹æ¯ä¸ªæ¡¶è¿›è¡Œæ’å…¥æ’åº
        for (int i = start + 1; i < start + size; i++)
        {
            uint64_t key = keys[i];
            GPUPoint3f point = points[i];
            int j = i - 1;

            // æ ‡å‡†æ’å…¥æ’åº
            while (j >= start && keys[j] > key)
            {
                keys[j + 1] = keys[j];
                points[j + 1] = points[j];
                j--;
            }
            keys[j + 1] = key;
            points[j + 1] = point;
        }
    }
    // åœ¨GPUBucketSort namespaceä¸­æ·»åŠ ï¼š

    __global__ void radixSortWithinBucketsKernel(
        GPUPoint3f *points,
        uint64_t *keys,
        GPUPoint3f *temp_points, // ä¸´æ—¶ç¼“å†²åŒº
        uint64_t *temp_keys,     // ä¸´æ—¶ç¼“å†²åŒº
        const int *bucket_offsets,
        const int *bucket_counts,
        int num_buckets)
    {

        int bucket_id = blockIdx.x;
        if (bucket_id >= num_buckets)
            return;

        int start = bucket_offsets[bucket_id];
        int size = bucket_counts[bucket_id];

        if (size <= 1)
            return;

        // ï¿½ ä¼˜åŒ–1: ä½¿ç”¨warpå†…åä½œï¼Œæ¯ä¸ªæ¡¶32ä¸ªçº¿ç¨‹
        int lane = threadIdx.x; // 0-31
        int warp_size = 32;

        // ä¼˜åŒ–2: 8ä½åŸºæ•°æ’åºï¼Œä½†å¹¶è¡Œå¤„ç†
        for (int pass = 0; pass < 8; pass++)
        {
            int shift = pass * 8;

            // ä¼˜åŒ–3: ä½¿ç”¨shared memoryå‡å°‘å…¨å±€å†…å­˜è®¿é—®
            __shared__ int shared_counts[256];

            // åˆå§‹åŒ–å…±äº«å†…å­˜è®¡æ•°å™¨ï¼ˆå¹¶è¡Œï¼‰
            for (int i = lane; i < 256; i += warp_size)
            {
                shared_counts[i] = 0;
            }
            __syncthreads();

            // Step 1: å¹¶è¡Œç»Ÿè®¡å­—èŠ‚å€¼å‡ºç°æ¬¡æ•°
            for (int i = lane; i < size; i += warp_size)
            {
                int digit = (keys[start + i] >> shift) & 0xFF;
                atomicAdd(&shared_counts[digit], 1);
            }
            __syncthreads();

            // Step 2: å¹¶è¡Œå‰ç¼€å’Œè®¡ç®—
            // ç®€å•çš„ä¸²è¡Œå‰ç¼€å’Œï¼ˆç”±å•çº¿ç¨‹å®Œæˆï¼Œå› ä¸ºåªæœ‰256ä¸ªå…ƒç´ ï¼‰
            if (lane == 0)
            {
                for (int i = 1; i < 256; i++)
                {
                    shared_counts[i] += shared_counts[i - 1];
                }
            }
            __syncthreads();

            // Step 3: å¹¶è¡Œåˆ†é…åˆ°ä¸´æ—¶æ•°ç»„
            //  ä¼˜åŒ–4: ä½¿ç”¨å±€éƒ¨åŸå­æ“ä½œå‡å°‘å†²çª
            for (int i = size - 1 - lane; i >= 0; i -= warp_size)
            {
                if (i >= 0)
                {
                    int digit = (keys[start + i] >> shift) & 0xFF;
                    int pos = atomicSub(&shared_counts[digit], 1) - 1;
                    temp_keys[start + pos] = keys[start + i];
                    temp_points[start + pos] = points[start + i];
                }
            }
            __syncthreads();

            // Step 4: å¹¶è¡Œå¤åˆ¶å›åŸæ•°ç»„
            for (int i = lane; i < size; i += warp_size)
            {
                keys[start + i] = temp_keys[start + i];
                points[start + i] = temp_points[start + i];
            }
            __syncthreads();
        }
    }

} // namespace GPUBucketSort

// ========== ROSæ¶ˆæ¯è§£åŒ…ç›¸å…³ ==========
// æ•°æ®ç±»å‹å¸¸é‡å®šä¹‰ï¼ˆä¸sensor_msgs::PointFieldä¸€è‡´ï¼‰
namespace {
    constexpr uint8_t POINT_FIELD_INT8 = 1;
    constexpr uint8_t POINT_FIELD_UINT8 = 2;
    constexpr uint8_t POINT_FIELD_INT16 = 3;
    constexpr uint8_t POINT_FIELD_UINT16 = 4;
    constexpr uint8_t POINT_FIELD_INT32 = 5;
    constexpr uint8_t POINT_FIELD_UINT32 = 6;
    constexpr uint8_t POINT_FIELD_FLOAT32 = 7;
    constexpr uint8_t POINT_FIELD_FLOAT64 = 8;
}

// æ•°æ®ç±»å‹è¯»å–è¾…åŠ©å‡½æ•°
__device__ inline float readFloat(const uint8_t* ptr, uint8_t datatype)
{
    switch (datatype)
    {
        case POINT_FIELD_FLOAT32:
            return *reinterpret_cast<const float*>(ptr);
        case POINT_FIELD_FLOAT64:
            return static_cast<float>(*reinterpret_cast<const double*>(ptr));
        case POINT_FIELD_INT8:
            return static_cast<float>(*reinterpret_cast<const int8_t*>(ptr));
        case POINT_FIELD_UINT8:
            return static_cast<float>(*reinterpret_cast<const uint8_t*>(ptr));
        case POINT_FIELD_INT16:
            return static_cast<float>(*reinterpret_cast<const int16_t*>(ptr));
        case POINT_FIELD_UINT16:
            return static_cast<float>(*reinterpret_cast<const uint16_t*>(ptr));
        case POINT_FIELD_INT32:
            return static_cast<float>(*reinterpret_cast<const int32_t*>(ptr));
        case POINT_FIELD_UINT32:
            return static_cast<float>(*reinterpret_cast<const uint32_t*>(ptr));
        default:
            return 0.0f; // ä¸æ”¯æŒçš„ç±»å‹ï¼Œè¿”å›0
    }
}

// ROSæ¶ˆæ¯è§£åŒ…å†…æ ¸
__global__ void unpackROSMsgKernel(
    const uint8_t* raw_data,
    GPUPoint3f* output_points,
    int point_step,
    int x_offset, int y_offset, int z_offset, int intensity_offset,
    uint8_t x_datatype, uint8_t y_datatype, uint8_t z_datatype, uint8_t intensity_datatype,
    size_t num_points
)
{
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= num_points)
        return;

    const uint8_t* point_data = raw_data + idx * point_step;
    GPUPoint3f& out = output_points[idx];

    // è§£æx, y, zï¼ˆå¿…é¡»å­˜åœ¨ï¼‰
    out.x = readFloat(point_data + x_offset, x_datatype);
    out.y = readFloat(point_data + y_offset, y_datatype);
    out.z = readFloat(point_data + z_offset, z_datatype);

    // è§£æintensityï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if (intensity_offset >= 0)
    {
        out.intensity = readFloat(point_data + intensity_offset, intensity_datatype);
    }
    else
    {
        out.intensity = 0.0f;
    }
}
